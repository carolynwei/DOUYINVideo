# -*- coding: utf-8 -*-
"""
éŸ³è‰²å·¥åŽ‚ - æ ¹æ®éŸ³è‰²IDåˆ›å»ºå¯¹åº”éŸ³è‰²å®žä¾‹
æ”¯æŒè‡ªåŠ¨è·¯ç”±å’Œé™çº§ç­–ç•¥
"""

from typing import Dict, Type, Optional, List
from .base_voice import BaseVoice, VoiceConfig
from .edge_voice import EdgeVoice
from .volc_voice import VolcVoice


class VoiceFactory:
    """
    éŸ³è‰²å·¥åŽ‚ç±»
    è´Ÿè´£åˆ›å»ºå’Œç®¡ç†éŸ³è‰²å®žä¾‹ï¼Œæ”¯æŒè‡ªåŠ¨è·¯ç”±
    """
    
    # éŸ³è‰²æ³¨å†Œè¡¨
    _voice_registry: Dict[str, Dict] = {
        # Edge TTS éŸ³è‰²
        "zh-CN-YunxiNeural": {"engine": "edge", "key": "yunxi", "class": EdgeVoice},
        "zh-CN-XiaoxiaoNeural": {"engine": "edge", "key": "xiaoxiao", "class": EdgeVoice},
        "zh-CN-YunyeNeural": {"engine": "edge", "key": "yunye", "class": EdgeVoice},
        "zh-CN-XiaoyiNeural": {"engine": "edge", "key": "xiaoyi", "class": EdgeVoice},
        
        # ç«å±±å¼•æ“ŽéŸ³è‰²
        "volc_lingcheng_wanqu": {"engine": "volc", "key": "lingcheng", "class": VolcVoice},
        "volc_xinglin_chengshu": {"engine": "volc", "key": "xinglin", "class": VolcVoice},
        "volc_mingxuan_qingsu": {"engine": "volc", "key": "mingxuan", "class": VolcVoice},
        "volc_yanping_tianmei": {"engine": "volc", "key": "yanping", "class": VolcVoice},
        "volc_yuanfeng_huoli": {"engine": "volc", "key": "yuanfeng", "class": VolcVoice},
    }
    
    # æ˜¾ç¤ºåç§°æ˜ å°„
    _display_names: Dict[str, str] = {
        "zh-CN-YunxiNeural": "ðŸŽ™ï¸ äº‘å¸Œ (æŠ–éŸ³çƒ­é—¨)",
        "zh-CN-XiaoxiaoNeural": "ðŸŽ™ï¸ æ™“æ™“ (æ¸©æŸ”å¥³å£°)",
        "zh-CN-YunyeNeural": "ðŸŽ™ï¸ äº‘é‡Ž (ç£æ€§ç”·å£°)",
        "zh-CN-XiaoyiNeural": "ðŸŽ™ï¸ æ™“ä¼Š (æ´»æ³¼å¥³å£°)",
        "volc_lingcheng_wanqu": "ðŸ”¥ ç«å±±-æ¸©æŸ”å¥³å£°",
        "volc_xinglin_chengshu": "ðŸ”¥ ç«å±±-æˆç†Ÿç”·å£°",
        "volc_mingxuan_qingsu": "ðŸ”¥ ç«å±±-æš´èºè€å“¥",
        "volc_yanping_tianmei": "ðŸ”¥ ç«å±±-ç”œç¾Žå¥³å£°",
        "volc_yuanfeng_huoli": "ðŸ”¥ ç«å±±-æ´»åŠ›å°‘å¹´",
    }
    
    @classmethod
    def create(cls, voice_id: str) -> Optional[BaseVoice]:
        """
        åˆ›å»ºéŸ³è‰²å®žä¾‹
        
        Args:
            voice_id: éŸ³è‰²ID
        
        Returns:
            éŸ³è‰²å®žä¾‹ï¼Œå¦‚æžœæ‰¾ä¸åˆ°åˆ™è¿”å›žNone
        """
        voice_info = cls._voice_registry.get(voice_id)
        if not voice_info:
            return None
        
        voice_class = voice_info["class"]
        voice_key = voice_info["key"]
        
        return voice_class(voice_key)
    
    @classmethod
    def create_with_fallback(cls, voice_id: str) -> BaseVoice:
        """
        åˆ›å»ºéŸ³è‰²å®žä¾‹ï¼Œå¦‚æžœä¸å¯ç”¨åˆ™è‡ªåŠ¨é™çº§
        
        Args:
            voice_id: é¦–é€‰éŸ³è‰²ID
        
        Returns:
            å¯ç”¨çš„éŸ³è‰²å®žä¾‹
        """
        # å°è¯•åˆ›å»ºé¦–é€‰éŸ³è‰²
        voice = cls.create(voice_id)
        if voice and voice.is_available():
            return voice
        
        # å¦‚æžœæ˜¯ç«å±±å¼•æ“Žå¤±è´¥ï¼Œé™çº§åˆ° Edge TTS
        if voice_id.startswith("volc_"):
            print(f"âš ï¸ ç«å±±å¼•æ“Žä¸å¯ç”¨ï¼Œé™çº§åˆ° Edge TTS")
            fallback = cls.create("zh-CN-YunxiNeural")
            if fallback:
                return fallback
        
        # é»˜è®¤è¿”å›žäº‘å¸Œ
        default = cls.create("zh-CN-YunxiNeural")
        if default:
            return default
        
        # æœ€åŽçš„å…œåº•
        return EdgeVoice("yunxi")
    
    @classmethod
    def get_display_name(cls, voice_id: str) -> str:
        """èŽ·å–æ˜¾ç¤ºåç§°"""
        return cls._display_names.get(voice_id, voice_id)
    
    @classmethod
    def list_all_voices(cls) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨éŸ³è‰²ID"""
        return list(cls._display_names.keys())
    
    @classmethod
    def list_edge_voices(cls) -> List[str]:
        """åˆ—å‡º Edge TTS éŸ³è‰²"""
        return [vid for vid in cls._display_names.keys() if not vid.startswith("volc_")]
    
    @classmethod
    def list_volc_voices(cls) -> List[str]:
        """åˆ—å‡ºç«å±±å¼•æ“ŽéŸ³è‰²"""
        return [vid for vid in cls._display_names.keys() if vid.startswith("volc_")]
    
    @classmethod
    def get_voice_mapping(cls) -> Dict[str, str]:
        """
        èŽ·å–éŸ³è‰²æ˜ å°„ï¼ˆç”¨äºŽStreamlitä¸‹æ‹‰æ¡†ï¼‰
        
        Returns:
            {æ˜¾ç¤ºåç§°: voice_id}
        """
        return {name: vid for vid, name in cls._display_names.items()}
    
    @classmethod
    def get_default_voice(cls) -> BaseVoice:
        """èŽ·å–é»˜è®¤éŸ³è‰²ï¼ˆäº‘å¸Œï¼‰"""
        return cls.create("zh-CN-YunxiNeural") or EdgeVoice("yunxi")
    
    @classmethod
    def register_voice(cls, voice_id: str, voice_class: Type[BaseVoice], 
                       voice_key: str, display_name: str, engine: str = "custom"):
        """
        æ³¨å†Œæ–°éŸ³è‰²
        
        Args:
            voice_id: éŸ³è‰²å”¯ä¸€æ ‡è¯†
            voice_class: éŸ³è‰²ç±»
            voice_key: éŸ³è‰²åœ¨ç±»ä¸­çš„é”®å
            display_name: æ˜¾ç¤ºåç§°
            engine: å¼•æ“Žç±»åž‹
        """
        cls._voice_registry[voice_id] = {
            "engine": engine,
            "key": voice_key,
            "class": voice_class
        }
        cls._display_names[voice_id] = display_name


class VoiceRouter:
    """
    éŸ³è‰²è·¯ç”±å™¨
    æ ¹æ®åœºæ™¯/æƒ…ç»ªè‡ªåŠ¨é€‰æ‹©æœ€ä½³éŸ³è‰²
    """
    
    # åœºæ™¯åˆ°éŸ³è‰²çš„æ˜ å°„
    SCENE_VOICE_MAP = {
        "çŸ¥è¯†ç§‘æ™®": "zh-CN-YunyeNeural",      # äº‘é‡Ž - ç£æ€§æƒå¨
        "æƒ…æ„Ÿæ²»æ„ˆ": "zh-CN-XiaoxiaoNeural",   # æ™“æ™“ - æ¸©æŸ”å¥³å£°
        "æžç¬‘å¨±ä¹": "zh-CN-XiaoyiNeural",     # æ™“ä¼Š - æ´»æ³¼å¥³å£°
        "çƒ­è¡€åŠ±å¿—": "volc_xinglin_chengshu",  # ç«å±±æˆç†Ÿç”·å£°
        "æ¸©æŸ”èŒç³»": "volc_yanping_tianmei",   # ç«å±±ç”œç¾Žå¥³å£°
        "åæ§½åæ§½": "volc_mingxuan_qingsu",   # ç«å±±æš´èºè€å“¥
        "é»˜è®¤": "zh-CN-YunxiNeural",          # äº‘å¸Œ - é€šç”¨
    }
    
    @classmethod
    def route_by_scene(cls, scene: str) -> str:
        """
        æ ¹æ®åœºæ™¯æŽ¨èéŸ³è‰²
        
        Args:
            scene: åœºæ™¯æè¿°
        
        Returns:
            voice_id
        """
        for key, voice_id in cls.SCENE_VOICE_MAP.items():
            if key in scene:
                return voice_id
        return cls.SCENE_VOICE_MAP["é»˜è®¤"]
    
    @classmethod
    def route_by_emotion(cls, emotion: str) -> str:
        """
        æ ¹æ®æƒ…ç»ªæŽ¨èéŸ³è‰²
        
        Args:
            emotion: æƒ…ç»ªæ ‡ç­¾
        
        Returns:
            voice_id
        """
        emotion_map = {
            "angry": "volc_mingxuan_qingsu",      # æ„¤æ€’ -> æš´èºè€å“¥
            "gentle": "zh-CN-XiaoxiaoNeural",     # æ¸©æŸ” -> æ™“æ™“
            "excited": "zh-CN-XiaoyiNeural",      # å…´å¥‹ -> æ™“ä¼Š
            "serious": "zh-CN-YunyeNeural",       # ä¸¥è‚ƒ -> äº‘é‡Ž
            "cute": "volc_yanping_tianmei",       # å¯çˆ± -> ç”œç¾Žå¥³å£°
        }
        return emotion_map.get(emotion, "zh-CN-YunxiNeural")
