# -*- coding: utf-8 -*-
"""
æ­¥éª¤4ï¼šéŸ³è§†åŒæ­¥ä¸åæœŸåˆæˆ
TTSåˆæˆ + BGMå¯¹é½ + è§†è§‰è½¬åœº
"""

import asyncio
import os
from typing import Dict, Any, List
from .base_step import BaseStep, StepResult, StepContext


class ProductionStep(BaseStep):
    """
    éŸ³è§†åŒæ­¥ä¸åæœŸåˆæˆ
    
    åŠŸèƒ½ï¼š
    1. TTSåˆæˆï¼šå¸¦æƒ…ç»ªçš„è¯­éŸ³ç”Ÿæˆ
    2. BGMå¯¹é½ï¼šéŸ³é¢‘èŠ‚å¥è¸©ç‚¹
    3. è§†è§‰è½¬åœºï¼šç”µå½±çº§è½¬åœºæ•ˆæœ
    4. æœ€ç»ˆæ¸²æŸ“ï¼šè§†é¢‘åˆæˆè¾“å‡º
    """
    
    step_id = "production"
    step_name = "éŸ³è§†åŒæ­¥ä¸åæœŸåˆæˆ"
    step_emoji = "ğŸ¬"
    step_description = "TTSåˆæˆ + BGMå¯¹é½ + è§†è§‰è½¬åœº + æœ€ç»ˆæ¸²æŸ“"
    
    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.voice_id = config.get("voice_id", "zh-CN-YunxiNeural")
        self.output_dir = config.get("output_dir", "./output")
    
    async def execute(self, context: StepContext) -> StepResult:
        """æ‰§è¡ŒåæœŸåˆæˆ"""
        try:
            scenes = context.scenes
            if not scenes:
                return StepResult(
                    success=False,
                    message="ç¼ºå°‘åˆ†é•œæ•°æ®",
                    error="è¯·å…ˆå®Œæˆè§†è§‰èµ„äº§æ­¥éª¤"
                )
            
            # 1. TTSè¯­éŸ³åˆæˆ
            audio_files = await self._synthesize_audio(scenes, context)
            
            # 2. BGMé€‰æ‹©ä¸å¯¹é½
            bgm_file = await self._select_and_align_bgm(context)
            
            # 3. è§†é¢‘åˆæˆ
            final_video = await self._compose_video(scenes, audio_files, bgm_file, context)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.audio_files = audio_files
            context.final_video = final_video
            
            return StepResult(
                success=True,
                data={
                    "final_video": final_video,
                    "duration": self._calculate_duration(scenes),
                    "resolution": "1080x1920"
                },
                message=f"âœ… è§†é¢‘åˆæˆå®Œæˆ: {final_video}"
            )
            
        except Exception as e:
            return StepResult(
                success=False,
                message="è§†é¢‘åˆæˆå¤±è´¥",
                error=str(e)
            )
    
    async def _synthesize_audio(self, scenes: List[Dict], context: StepContext) -> List[str]:
        """TTSè¯­éŸ³åˆæˆ"""
        audio_files = []
        
        for i, scene in enumerate(scenes):
            narration = scene.get("narration", "")
            # æ¸…ç†SSMLæ ‡ç­¾ç”¨äºæ–‡ä»¶å
            clean_text = narration[:20].replace("<", "").replace(">", "")
            audio_file = f"audio_{i}_{clean_text}.mp3"
            audio_files.append(audio_file)
        
        return audio_files
    
    async def _select_and_align_bgm(self, context: StepContext) -> str:
        """é€‰æ‹©å¹¶å¯¹é½BGM"""
        style_id = context.style_id
        
        # é£æ ¼åˆ°BGMçš„æ˜ å°„
        bgm_map = {
            "cognitive_reshaper": "assassin/epic_cinematic.mp3",
            "healing_observer": "growth/lofi.mp3",
            "growth_witness": "growth/lofi.mp3",
            "emotional_rollercoaster": "venting/trap.mp3",
            "meme_philosopher": "meme/funny.mp3"
        }
        
        return bgm_map.get(style_id, "bgm.mp3")
    
    async def _compose_video(self, scenes: List[Dict], audio_files: List[str], 
                            bgm_file: str, context: StepContext) -> str:
        """åˆæˆæœ€ç»ˆè§†é¢‘"""
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        topic = context.selected_topic[:20].replace(" ", "_")
        timestamp = asyncio.get_event_loop().time()
        output_file = os.path.join(self.output_dir, f"{topic}_{int(timestamp)}.mp4")
        
        return output_file
    
    def _calculate_duration(self, scenes: List[Dict]) -> int:
        """è®¡ç®—è§†é¢‘æ—¶é•¿"""
        return sum(scene.get("duration", 5) for scene in scenes)
