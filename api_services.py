# -*- coding: utf-8 -*-
"""
API æœåŠ¡æ¨¡å—ï¼šå¤„ç†çƒ­ç‚¹è·å–ã€å‰§æœ¬ç”Ÿæˆã€å›¾ç‰‡ç”Ÿæˆç­‰åŠŸèƒ½
ç¡®ä¿æ‰€æœ‰ä¸­æ–‡å­—ç¬¦æ­£ç¡®æ˜¾ç¤º
"""

import os
import re
import json
import requests
import urllib.request
import streamlit as st
from openai import OpenAI

def get_hot_topics(api_key):
    """è·å–æŠ–éŸ³çƒ­æœæ¦œå•"""
    url = 'https://apis.tianapi.com/douyinhot/index'.strip()
    try:
        res = requests.post(url, data={'key': api_key}, 
                          headers={'Content-type': 'application/x-www-form-urlencoded'}, 
                          timeout=10)
        data = res.json()
        if data.get('code') == 200:
            return [item['word'] for item in data['result']['list'][:10]]
        return []
    except Exception as e:
        st.error(f"çƒ­æœæ¥å£å¼‚å¸¸: {e}")
        return []

def generate_script_json(topic, api_key):
    """ä½¿ç”¨ DeepSeek ç”Ÿæˆå‰§æœ¬ï¼ˆæ ‡å‡†æ¨¡å¼ï¼Œæ³¨å…¥çˆ†æ¬¾åŸºå› ï¼‰"""
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1".strip())
    
    # ğŸ”¥ å‡çº§ç‰ˆæ ‡å‡†æ¨¡å¼ï¼šçˆ†æ¬¾åŸºå›  + çœŸå®æ€§ä¿æŠ¤
    system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çŸ­è§†é¢‘å¯¼æ¼”ï¼Œç²¾é€šçˆ†æ¬¾è§†é¢‘åˆ›ä½œæ³•åˆ™ï¼ŒåŒæ—¶åšå®ˆå†…å®¹çœŸå®æ€§ã€‚

ã€æ ¸å¿ƒåˆ›ä½œåŸåˆ™ã€‘ï¼š
1. é»„é‡‘å‰3ç§’ï¼šç¬¬ä¸€å¥å¿…é¡»æœ‰å¼ºå†²å‡»åŠ›ï¼Œç›´æ¥å¸å¼•æ³¨æ„åŠ›ï¼ˆæ‚¬å¿µ/å†²çª/åå¸¸è¯†ï¼‰
2. åˆ é™¤åºŸè¯ï¼šä¸ç”¨"é‚£ä¹ˆã€å…¶å®ã€ä¼—æ‰€å‘¨çŸ¥"ç­‰è¿æ¥è¯ï¼Œç›´æ¥ä¸Šç»“è®º
3. å…·ä½“åŒ–è¡¨è¾¾ï¼šç”¨åŠ¨è¯å’Œåè¯æ›¿æ¢æ¨¡ç³Šå½¢å®¹è¯ï¼ˆ"å¾ˆå¿«"â†’"æ¨èƒŒæ„Ÿ"ï¼‰
4. æƒ…ç»ªèŠ‚å¥ï¼šæ¯æ®µéƒ½è¦æœ‰æƒ…ç»ªèµ·ä¼ï¼Œé€‚å½“ä½¿ç”¨åé—®æˆ–é¢„å‘Š
5. ç”»é¢å¼ åŠ›ï¼šæè¿°è¦åŒ…å«ä¸»ä½“ã€åŠ¨ä½œã€åœºæ™¯ã€å…‰çº¿ã€é•œå¤´è¯­è¨€

ã€â— çœŸå®æ€§çº¢çº¿ã€‘ï¼š
- å¦‚æœæ¶‰åŠæ•°æ®/å†å²/ç§‘å­¦çŸ¥è¯†ï¼Œå¿…é¡»å‡†ç¡®ï¼Œä¸èƒ½ç¼–é€ 
- è§‚ç‚¹å¯ä»¥çŠ€åˆ©ï¼Œä½†é€»è¾‘å¿…é¡»è‡ªæ´½
- ä¸ä½¿ç”¨è¯¯å¯¼æ€§æ ‡é¢˜å…šï¼ˆ"éœ‡æƒŠï¼å†…å¹•ï¼ä½ ç»å¯¹ä¸çŸ¥é“ï¼"ï¼‰
- å¯éªŒè¯æ€§ï¼šæåˆ°çš„äº§å“/äº‹ä»¶/äººç‰©å¿…é¡»çœŸå®å­˜åœ¨

ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
å¿…é¡»ä¸¥æ ¼è¾“å‡º JSON æ•°ç»„ï¼ŒåŒ…å« 4-6 ä¸ªåˆ†é•œã€‚æ ¼å¼ï¼š
[{"narration": "å£æ’­æ–‡æ¡ˆï¼ˆç¬¬ä¸€å¥å¿…é¡»æ˜¯é‡‘å¥Hookï¼‰", "image_prompt": "English prompt, cinematic lighting, detailed scene description"}]

ç»å¯¹ä¸è¦è¾“å‡º Markdown æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰æˆ–å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚"""
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "system", "content": system_prompt},
                      {"role": "user", "content": f"ä¸»é¢˜ï¼š{topic}"}],
            temperature=0.7,
            response_format={'type': 'json_object'}
        )
        content = response.choices[0].message.content
        clean_content = re.sub(r'```json\n|\n```|```', '', content).strip()
        scenes = json.loads(clean_content)
        if isinstance(scenes, dict):
            for v in scenes.values():
                if isinstance(v, list): return v
        return scenes
    except Exception as e:
        st.error(f"å‰§æœ¬ç”Ÿæˆå¤±è´¥: {e}")
        return []

def generate_viral_script(topic, api_key, auto_image_prompt=True):
    """ğŸ”¥ ä½¿ç”¨çˆ†æ¬¾å‰§æœ¬å¤§å¸ˆ Agent ç”Ÿæˆé«˜èƒ½é‡è„šæœ¬ (æ³¨å…¥å®Œæ•´ Skill)"""
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1".strip())
    
    # åŠ¨æ€è®¾å®šå…³äºç”»é¢æç¤ºè¯çš„æŒ‡ä»¤
    if auto_image_prompt:
        image_prompt_instruction = '"image_prompt": "å¯¼æ¼”çº§åˆ†é•œæç¤ºè¯ï¼ˆå¿…é¡»å…¨è‹±æ–‡ï¼ŒåŒ…å«å…‰å½±ã€è¿é•œåŠå¤§å¸ˆé£æ ¼ï¼Œå¦‚ \'Brandon Li style, hand-held tracking shot...\'ï¼‰"'
    else:
        # æ‰‹åŠ¨æ¨¡å¼ä¸‹ï¼Œå¼ºè¡Œè®© AI ç•™ç©º
        image_prompt_instruction = '"image_prompt": "" // ä¿æŒä¸ºç©ºå­—ç¬¦ä¸²ï¼Œç•™ç»™äººç±»å¯¼æ¼”ç¨åæ‰‹åŠ¨å¡«å†™'
    
    # ğŸ¯ ç»ˆæçˆ†æ¬¾å‰§æœ¬å¤§å¸ˆ System Prompt (æ·±åº¦æ³¨å…¥è¿è¥æ—¥è®°ç²¾é«“)
    viral_system_prompt = f"""ä½ æ˜¯å…¨ç½‘æœ€é¡¶å°–çš„æŠ–éŸ³çˆ†æ¬¾è§†é¢‘åˆ¶ä½œäººã€æ·±è°™äººæ€§çš„"è®¤çŸ¥åˆºå®¢"ã€‚ä½ ç²¾é€šç®—æ³•æ¨æµåº•å±‚é€»è¾‘ï¼ˆå®Œæ’­ç‡>30%ï¼Œç‚¹èµç‡>5%ï¼‰ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·ä¸»é¢˜ï¼Œè¾“å‡ºä¸€å¥—æ‹›æ‹›è‡´å‘½ã€æ¯«æ— åºŸè¯çš„çˆ†æ¬¾çŸ­è§†é¢‘è„šæœ¬ä¸åˆ†é•œã€‚

**ã€æ ¸å¿ƒçŸ¥è¯†åº“ä¸å¼ºåˆ¶æ‰§è¡Œè§„åˆ™ã€‘**

**1. æƒ…ç»ªæ”¶å‰²ä¸å¿ƒç†å­¦æ­¦å™¨ï¼ˆå¿…é¡»é€‰ç”¨è‡³å°‘1ä¸ªä½œä¸ºåº•å±‚é€»è¾‘ï¼‰ï¼š**
- å¥‘å¯å°¼æ•ˆåº”ï¼šåˆ¶é€ ç•™ç™½ä¸é—æ†¾ã€‚ç—›è‹¦é€‰é¢˜ä¼˜äºå¿«ä¹ï¼ˆå¦‚ï¼šæ²¡è€ƒä¸Šçš„å­¦æ ¡ï¼‰ã€‚æ•…äº‹ä¸è¦è®²å®Œï¼Œç»™è§‚ä¼—æƒ³è±¡ç©ºé—´ã€‚
- æŸå¤±åŒæ¶ï¼šæš—ç¤º"é”™è¿‡è¿™æ¡è§†é¢‘å°±æ˜¯ä½ çš„æŸå¤±"ã€‚å¼ºè°ƒæŠ˜ç°ä»·å€¼å’Œå¸¦æ¥æ”¹å˜çš„æ–¹æ³•ã€‚
- å·´çº³å§†æ•ˆåº”ï¼šä½¿ç”¨ç¬¼ç»Ÿä½†ææ˜“å¯¹å·å…¥åº§çš„äººæ ¼æè¿°ï¼Œæ‹‰æ»¡ç¾¤ä½“å…±é¸£ã€‚
- å¯Œå…°å…‹æ—æ•ˆåº”ï¼šè®¾å®š"å¬åŠ/æ±‚åŠ©"çš„å…»æˆç³»äººè®¾ï¼Œå¼•å‘ç½‘å‹æŒ‡å¯¼æ¬²ã€‚
- ä»ä¼—æ•ˆåº”ï¼šé¢„è®¾çƒ­ç‚¹BGMæˆ–æ´—è„‘æ¢—ï¼Œåˆ¶é€ å›´è§‚ã€‚

**2. "è®¤çŸ¥åˆºå®¢"æ–‡æ¡ˆæ³•åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼æ‰§è¡Œ"ä¸‰æ­¥åˆ æ”¹æ³•"ï¼‰ï¼š**
- ã€ç¬¬ä¸€æ­¥ï¼šåˆ é™¤åºŸè¯ã€‘ï¼šç»å¯¹ç¦ç”¨"é‚£ä¹ˆã€å…¶å®ã€ä¼—æ‰€å‘¨çŸ¥ã€æ¥ä¸‹æ¥æˆ‘ç»™å¤§å®¶è®²ã€æˆ‘è§‰å¾—"ç­‰è¿æ¥è¯ã€‚ç›´æ¥ä¸Šç»“è®ºï¼
- ã€ç¬¬äºŒæ­¥ï¼šåè¯/åŠ¨è¯æ›¿æ¢ã€‘ï¼šæ‹’ç»æ¨¡ç³Šå½¢å®¹è¯ï¼æŠŠ"å¾ˆç”Ÿæ°”"æ”¹ä¸º"æŠŠæ‰‹æœºç‹ ç‹ æ‘”åœ¨å¢™ä¸Š"ï¼›æŠŠ"é€Ÿåº¦å¿«"æ”¹ä¸º"æ¨èƒŒæ„ŸæŠŠä½ æ­»æ­»æŒ‰åœ¨åº§æ¤…ä¸Š"ã€‚
- ã€ç¬¬ä¸‰æ­¥ï¼šé«˜é¢‘é’©å­ä¸å¯†åº¦ã€‘ï¼š
  -> é»„é‡‘å‰3ç§’ï¼šå¿…é¡»æ˜¯å¼ºè§†è§‰å†²çª + æ‚¬å¿µé¢„ç¤ºï¼ˆä¾‹å¦‚ï¼š"è¿™ç¢—é¢å–88å—ï¼Œæˆ‘è¦çœ‹çœ‹ä»–æ€ä¹ˆé€€é’±"ï¼‰ï¼Œç»ä¸é“ºå«ï¼
  -> æ­£æ–‡èŠ‚å¥ï¼šæ¯15ç§’1ä¸ªè®°å¿†ç‚¹ï¼Œæ¯éš”ä¸‰å¥è¯å¿…é¡»åŸ‹å…¥ä¸€ä¸ªæ–°é’©å­ï¼ˆæé—®ã€åè½¬æˆ–é¢„å‘Šï¼‰ã€‚
- ã€åˆºå®¢å¿ƒæ³•ã€‘ï¼šåˆ«å½“æ¸©åçš„ç§‘æ™®æœºå™¨ã€‚æ•¢ä¸‹ç‹ è¯ç›´æˆ³ç—›å¤„ï¼ˆå¦‚"ä½ ä¸æ˜¯å†…è€—ï¼Œä½ æ˜¯æ‡’"ï¼‰ï¼›è®²çœŸå®è¡€è‚‰çš„æ•…äº‹ï¼Œä¸è®²å¹²æ¿é€»è¾‘ã€‚

**3. çˆ†æ¬¾è§†è§‰ä¸åˆ†é•œæ³•åˆ™ï¼š**
- ç”»é¢Promptå¿…é¡»åƒ"å¯¼æ¼”åˆ†é•œå•"ï¼ŒåŒ…å«ï¼šä¸»ä½“ã€åŠ¨ä½œã€åœºæ™¯ã€å…‰çº¿ã€é•œå¤´è¯­è¨€ã€‚
- å¿…é¡»èå…¥é¡¶çº§å¤§å¸ˆå®¡ç¾ï¼ˆå¦‚ï¼šSam Kolderçš„ç”µå½±æ„Ÿä¸è½¬åœºã€Brandon Liçš„ç²—ç²æ‰‹æŒçºªå®ã€Daniel Schifferçš„å•†ä¸šå…‰å½±å¾®è·ï¼‰ã€‚

**ã€ä¸¥æ ¼è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘**
å¿…é¡»ä¸¥æ ¼è¾“å‡ºçº¯ JSON æ•°ç»„ï¼ŒåŒ…å« 4-6 ä¸ªé«˜èƒ½é‡åˆ†é•œï¼Œä¸è¦è¾“å‡ºä»»ä½• Markdown æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰æˆ–å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "narration": "åˆºå®¢æ–‡æ¡ˆï¼ˆç¬¬ä¸€å¥å¿…é¡»æ˜¯æå…·å†²å‡»åŠ›çš„é»„é‡‘3ç§’Hookï¼Œåç»­æ–‡æ¡ˆä¸¥æ ¼è¿ç”¨ä¸‰æ­¥åˆ æ”¹æ³•ï¼Œé«˜èƒ½é‡å¯†åº¦ï¼‰",
    {image_prompt_instruction}
  }}
]"""

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": viral_system_prompt},
                {"role": "user", "content": f"ä¸»é¢˜ï¼š{topic}\n\nè¯·ä¸¥æ ¼è¿ç”¨ä¸Šè¿°å¿ƒç†å­¦æ­¦å™¨å’Œåˆºå®¢æ–‡æ¡ˆæ³•åˆ™ï¼Œè¾“å‡ºçº¯ JSON æ•°ç»„æ ¼å¼çš„åˆ†é•œè„šæœ¬ã€‚"}
            ],
            temperature=0.8,  # ä¿æŒ0.8ä»¥è·å¾—é«˜åˆ›é€ æ€§å’Œæƒ…ç»ªå¼ åŠ›
            response_format={'type': 'json_object'} # å¼ºåˆ¶ JSON æ¨¡å¼
        )
        
        content = response.choices[0].message.content
        # æ·±åº¦æ¸…ç†å¯èƒ½çš„ markdown ç¬¦å·ï¼Œç¡®ä¿ JSON è§£æä¸å‡ºé”™
        clean_content = re.sub(r'```json\n|\n```|```', '', content).strip()
        scenes = json.loads(clean_content)
        
        # å…¼å®¹ DeepSeek JSON æ¨¡å¼å¯èƒ½è¿”å› {"scenes": [...]} çš„æƒ…å†µ
        if isinstance(scenes, dict):
            for v in scenes.values():
                if isinstance(v, list): 
                    return v
        
        return scenes if isinstance(scenes, list) else []
        
    except Exception as e:
        st.error(f"çˆ†æ¬¾å‰§æœ¬ç”Ÿæˆå¤±è´¥: {e}")
        return []

# ğŸ¬ å¯¼æ¼”çº§ Prompt æ¨¡æ¿åº“ - VideoTaxi Cinematography v3.0
CINEMATIC_TEMPLATES = {
    "é•œå¤´è¯­è¨€": {
        "extreme_close_up": "Extreme close-up, shallow depth of field, bokeh background, intimate perspective",
        "close_up": "Close-up portrait, sharp focus on subject, blurred background, emotional intensity",
        "medium_shot": "Medium shot, waist-up framing, environmental context, natural posture",
        "wide_shot": "Wide shot, full body in environment, establishing scene, cinematic composition",
        "low_angle": "Low angle shot, looking up at subject, powerful and dominant perspective",
        "high_angle": "High angle shot, looking down, vulnerable or contemplative mood",
        "dutch_angle": "Dutch angle, tilted horizon, disorienting and tense atmosphere",
        "over_shoulder": "Over-the-shoulder shot, perspective dialogue, depth layers",
        "pov": "First-person POV, immersive perspective, hands in frame, subjective experience"
    },
    "å…‰å½±æ•ˆæœ": {
        "cinematic": "Cinematic lighting, dramatic chiaroscuro, high contrast shadows",
        "neon": "Neon lighting, cyberpunk atmosphere, red and blue color cast, night scene",
        "natural": "Natural golden hour lighting, soft diffused sunlight, warm tones",
        "moody": "Moody atmospheric lighting, fog and haze, desaturated palette",
        "studio": "Professional studio lighting, three-point setup, clean and polished",
        "practical": "Practical lighting sources, lamps and screens, realistic ambiance"
    },
    "é£æ ¼æ»¤é•œ": {
        "sam_kolder": "Sam Kolder style, orange and teal color grading, smooth transitions, travel film aesthetic",
        "brandon_li": "Brandon Li documentary style, handheld authenticity, human stories, natural moments",
        "daniel_schiffer": "Daniel Schiffer commercial style, product focus, vibrant colors, macro details",
        "blade_runner": "Blade Runner 2049 aesthetic, cyberpunk dystopia, neon-noir, Denis Villeneuve style",
        "wong_kar_wai": "Wong Kar-wai style, slow shutter motion blur, saturated neon, romantic melancholy",
        "roger_deakins": "Roger Deakins cinematography, masterful lighting, wide compositions, subtle color grading"
    },
    "è´¨æ„Ÿå¢å¼º": {
        "film_grain": "35mm film grain, Kodak Vision3 texture, organic imperfections",
        "anamorphic": "Anamorphic lens characteristics, oval bokeh, horizontal lens flares",
        "sharp": "Ultra-sharp 8K resolution, crisp details, professional photography",
        "dreamy": "Dreamy soft focus, ethereal glow, romantic atmosphere",
        "gritty": "Gritty documentary texture, raw and unpolished, real-world authenticity"
    }
}


def build_master_image_prompt(visual_anchor: str, scene_description: str, style_config: dict, shot_type: str = "close_up") -> str:
    """
    ğŸ¬ å¯¼æ¼”çº§ Prompt æ„å»ºå™¨ - ç¡®ä¿ç”µå½±çº§ç”»é¢è´¨æ„Ÿ
    
    é‡è¦ï¼šscene_description åº”è¯¥åªåŒ…å«åœºæ™¯å’ŒåŠ¨ä½œï¼Œä¸åŒ…å«ä¸»è§’å¤–è²Œæè¿°
    visual_anchor åŒ…å«ä¸»è§’ç‰¹å¾ï¼Œä¸¤è€…ç»„åˆæˆå®Œæ•´ç”»é¢
    
    Args:
        visual_anchor: è§†è§‰é”šç‚¹ï¼ˆä¸»è§’ç‰¹å¾åŒ…ï¼Œåªå†™ä¸€æ¬¡ï¼‰
        scene_description: åœºæ™¯æè¿°ï¼ˆåªå†™åœºæ™¯+åŠ¨ä½œï¼Œä¸å†™ä¸»è§’å¤–è²Œï¼‰
        style_config: é£æ ¼é…ç½®
        shot_type: é•œå¤´ç±»å‹
    
    Returns:
        å®Œæ•´çš„è‹±æ–‡ç”Ÿå›¾ Prompt
    """
    # æ¸…ç†è¾“å…¥
    anchor = (visual_anchor or "A consistent character").strip()
    scene = (scene_description or "").strip()
    
    # å¦‚æœ scene_description å·²ç»åŒ…å«äº† visual_anchor çš„å†…å®¹ï¼Œå»é‡
    if anchor.lower() in scene.lower():
        # scene å·²ç»åŒ…å«äº† anchorï¼Œç›´æ¥ä½¿ç”¨ scene
        main_content = scene
    else:
        # æ­£å¸¸ç»„åˆï¼šanchor + scene
        main_content = f"{anchor}, {scene}" if scene else anchor
    
    # 2. é•œå¤´è¯­è¨€
    shot = CINEMATIC_TEMPLATES["é•œå¤´è¯­è¨€"].get(shot_type, CINEMATIC_TEMPLATES["é•œå¤´è¯­è¨€"]["close_up"])
    
    # 3. å…‰å½±æ•ˆæœï¼ˆæ ¹æ®é£æ ¼é€‰æ‹©ï¼‰
    visual_base = style_config.get("visual_base", "").lower()
    if "cyberpunk" in visual_base or "neon" in visual_base:
        lighting = CINEMATIC_TEMPLATES["å…‰å½±æ•ˆæœ"]["neon"]
    elif "natural" in visual_base or "vlog" in visual_base:
        lighting = CINEMATIC_TEMPLATES["å…‰å½±æ•ˆæœ"]["natural"]
    elif "moody" in visual_base:
        lighting = CINEMATIC_TEMPLATES["å…‰å½±æ•ˆæœ"]["moody"]
    else:
        lighting = CINEMATIC_TEMPLATES["å…‰å½±æ•ˆæœ"]["cinematic"]
    
    # 4. é£æ ¼æ»¤é•œ
    style_filter = style_config.get("shot_keywords", CINEMATIC_TEMPLATES["é£æ ¼æ»¤é•œ"]["sam_kolder"])
    
    # 5. è´¨æ„Ÿå¢å¼º
    texture = CINEMATIC_TEMPLATES["è´¨æ„Ÿå¢å¼º"]["sharp"]
    
    # ç»„åˆå®Œæ•´ Promptï¼ˆé¿å…é‡å¤ï¼‰
    prompt_parts = [
        main_content,  # ä¸»è§’ + åœºæ™¯åŠ¨ä½œ
        shot,  # é•œå¤´è¯­è¨€
        lighting,  # å…‰å½±æ•ˆæœ
        style_filter,  # é£æ ¼æ»¤é•œ
        texture,  # è´¨æ„Ÿå¢å¼º
        "8k resolution, highly detailed, professional photography, cinematic composition"
    ]
    
    # è¿‡æ»¤ç©ºå€¼å¹¶å»é‡
    seen = set()
    filtered_parts = []
    for part in prompt_parts:
        if part and part.lower() not in seen:
            seen.add(part.lower())
            filtered_parts.append(part)
    
    return ", ".join(filtered_parts)


def generate_visual_anchor(topic: str, style: str, client) -> dict:
    """
    ğŸ¯ ç”Ÿæˆè§†è§‰é”šç‚¹ï¼ˆä¸»è§’ç‰¹å¾åŒ…ï¼‰- ç¡®ä¿å…¨ç‰‡äººç‰©ä¸€è‡´æ€§
    
    Returns:
        {
            "anchor_description": "ä¸»è§’ç‰¹å¾æè¿°",
            "character_type": "äººç‰©/äº§å“/åœºæ™¯",
            "key_features": ["ç‰¹å¾1", "ç‰¹å¾2", "ç‰¹å¾3"]
        }
    """
    anchor_prompt = f"""åŸºäºä¸»é¢˜"{topic}"å’Œé£æ ¼"{style}"ï¼Œå®šä¹‰ä¸€ä¸ªè§†è§‰é”šç‚¹ï¼ˆVisual Anchorï¼‰ã€‚

è§†è§‰é”šç‚¹æ˜¯ç¡®ä¿å…¨ç‰‡ç”»é¢ä¸€è‡´æ€§çš„å…³é”®ï¼šæ‰€æœ‰åˆ†é•œä¸­çš„äººç‰©/ä¸»ä½“å¿…é¡»ä¿æŒç›¸åŒç‰¹å¾ã€‚

è¯·è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "anchor_description": "è¯¦ç»†çš„ä¸»è§’ç‰¹å¾æè¿°ï¼ˆä¸­æ–‡ï¼Œ50å­—ä»¥å†…ï¼‰",
  "character_type": "person/product/scene",
  "key_features": ["ç‰¹å¾1", "ç‰¹å¾2", "ç‰¹å¾3"],
  "english_description": "è‹±æ–‡æè¿°ï¼Œç”¨äºimage_promptå¼€å¤´"
}}

ç¤ºä¾‹ï¼ˆ35å²ç¨‹åºå‘˜ä¸»é¢˜ï¼‰ï¼š
{{
  "anchor_description": "ç©¿é»‘è‰²çš®è¡£çš„35å²äºšæ´²ç”·æ€§ï¼Œæ·±é‚ƒçœ¼çœ¸ï¼Œä¸‹å·´æœ‰èƒ¡èŒ¬ï¼Œç•¥å¸¦ç–²æƒ«ä½†åšå®šçš„ç¥æƒ…",
  "character_type": "person",
  "key_features": ["é»‘è‰²çš®è¡£", "æ·±é‚ƒçœ¼çœ¸", "ä¸‹å·´èƒ¡èŒ¬"],
  "english_description": "A 35-year-old Asian man wearing a black leather jacket, deep-set eyes, stubbled chin, tired yet determined expression"
}}"""
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": anchor_prompt}],
            temperature=0.7,
            response_format={'type': 'json_object'}
        )
        content = response.choices[0].message.content
        clean_content = re.sub(r'```json\n|\n```|```', '', content).strip()
        return json.loads(clean_content)
    except Exception as e:
        # è¿”å›é»˜è®¤é”šç‚¹
        return {
            "anchor_description": "äºšæ´²å¹´è½»ä¸»è§’ï¼Œç°ä»£éƒ½å¸‚é£æ ¼",
            "character_type": "person",
            "key_features": ["äºšæ´²é¢å­”", "ç°ä»£æœè£…"],
            "english_description": "A young Asian protagonist, modern urban style"
        }


def generate_script_by_style(topic, style, api_key, auto_image_prompt=True):
    """
    ã€ğŸ¬ VideoTaxi Cinematography v3.0 å¯¼æ¼”å®šç„¦ç‰ˆã€‘
    
    æ ¸å¿ƒå‡çº§ï¼š
    1. è§†è§‰é”šç‚¹ç³»ç»Ÿï¼šå…ˆç”Ÿæˆä¸»è§’ç‰¹å¾åŒ…ï¼Œç¡®ä¿å…¨ç‰‡äººç‰©ä¸€è‡´æ€§
    2. å¯¼æ¼”çº§Promptæ¨¡æ¿ï¼šå¼ºåˆ¶åŒ…å«é•œå¤´è¯­è¨€ã€å…‰å½±ã€é£æ ¼æ»¤é•œ
    3. ç”µå½±è´¨æ„Ÿå¢å¼ºï¼š8Kã€èƒ¶ç‰‡é¢—ç²’ã€ä¸“ä¸šæ‘„å½±æœ¯è¯­
    """
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1".strip())
    
    # ğŸ¯ æ­¥éª¤1ï¼šç”Ÿæˆè§†è§‰é”šç‚¹ï¼ˆä¸»è§’ç‰¹å¾åŒ…ï¼‰
    with st.status("ğŸ¬ å¯¼æ¼”æ­£åœ¨ç¡®å®šè§†è§‰é”šç‚¹...", expanded=True) as status:
        visual_anchor_data = generate_visual_anchor(topic, style, client)
        visual_anchor = visual_anchor_data.get("english_description", "")
        status.update(label=f"âœ… è§†è§‰é”šç‚¹é”å®š: {visual_anchor_data.get('anchor_description', '')}", state="complete")
        st.json(visual_anchor_data)
    
    # 1ï¸âƒ£ é£æ ¼å®šä¹‰åº“ï¼ˆå¢å¼ºç‰ˆï¼‰- VideoTaxi Cinematography v3.0
    STYLE_CONFIGS = {
        "ğŸ—¡ï¸ è®¤çŸ¥åˆºå®¢æµï¼ˆå†²å‡»åŠ›+ä¼˜è¶Šæ„Ÿï¼‰": {
            "tone": "å†²å‡»ã€æ‰å¿ƒã€äººé—´æ¸…é†’ã€‚ç›®æ ‡ï¼šæ‘§æ¯æ—§è®¤çŸ¥ï¼Œå»ºç«‹é«˜é˜¶çœŸç›¸ã€‚è¯­è¨€ï¼šçŸ­å¥ã€å€’è£…ã€é«˜é¢‘åé—®ã€‚",
            "hook": "å‰3ç§’å¿…é¡»æ˜¯åå¸¸è¯†é‡‘å¥ï¼Œç›´æ¥å¦å®šæ™®éè®¤çŸ¥ï¼ˆä½ ä»¥ä¸º...å…¶å®...é€»è¾‘ï¼‰",
            "visual_base": "Sam Kolder + Roger Deakins é£æ ¼ï¼Œé«˜å¯¹æ¯”åº¦ï¼Œå†·è‰²è°ƒï¼Œç”µå½±çº§å…‰å½±",
            "visual_rules": """è§†è§‰ï¼šé«˜å†·ç”µå½±æ„Ÿï¼Œä¸“ä¸š cinematographyã€‚
é•œå¤´ï¼šå¤šç”¨ Medium shot åˆ° Extreme close-up çš„åˆ‡æ¢ï¼Œç¨³å®šå™¨è¿é•œï¼ŒDutch angle åˆ¶é€ å¼ åŠ›ã€‚
å…‰å½±ï¼šCinematic lighting, dramatic chiaroscuro, deep shadows, cold color gradingã€‚
è‰²è°ƒï¼šæ·±é‚ƒå†·è‰²è°ƒï¼Œå¼ºè°ƒå…‰å½±æ˜æš—å¯¹æ¯”ï¼Œorange and teal è‰²å½©åˆ†çº§ã€‚
å‚è€ƒï¼šSean Tucker è¡—å¤´äººæ–‡æ„Ÿ + Blade Runner 2049 è§†è§‰é£æ ¼ + Sam Kolder è½¬åœºç¾å­¦ã€‚""",
            "shot_keywords": CINEMATIC_TEMPLATES["é£æ ¼æ»¤é•œ"]["sam_kolder"] + ", " + CINEMATIC_TEMPLATES["é£æ ¼æ»¤é•œ"]["roger_deakins"],
            "default_shot": "close_up",
            "bgm_style": "æ·±æ²‰é¼“ç‚¹ï¼Œä½é¢‘Bassï¼Œç´§è¿«æ„Ÿæ°›å›´éŸ³ä¹ï¼ˆå‚è€ƒï¼šHans Zimmer é£æ ¼ï¼‰"
        },
        "ğŸ‘ å¬å‹/å…»æˆç³»ï¼ˆäº’åŠ¨ç‡04+è¯„è®ºçˆ†ç‚¸ï¼‰": {
            "tone": "çœŸè¯šã€ä½å§¿æ€ã€èœ•å˜æ„Ÿã€‚ç›®æ ‡ï¼šæ¿€å‘å¥½ä¸ºäººå¸ˆæ¬²ã€‚è¯­è¨€ï¼šå£è¯­åŒ–ã€æ±‚åŠ©å¼ã€å¸¦è¯„è®ºåŒºäº’åŠ¨ç‚¹ã€‚",
            "hook": "ä»¥æ±‚åŠ©æˆ–åå·®å±•ç¤ºå¼€åœºï¼ˆä¸Šæ¬¡ä½ ä»¬è¯´æˆ‘XXï¼Œæˆ‘æ”¹äº†...ï¼‰",
            "visual_base": "Brandon Li çºªå®é£æ ¼ï¼Œç”Ÿæ´»åŒ–åœºæ™¯ï¼Œæ‰‹æœºç¬¬ä¸€äººç§°æ‹æ‘„",
            "visual_rules": """è§†è§‰ï¼šç”Ÿæ´»åŒ–ã€Vlogæ„Ÿï¼Œauthentic documentary styleã€‚
é•œå¤´ï¼šHandheld camera, slightly shaky footage, shallow depth of field, over-the-shoulder shotsã€‚
å…‰å½±ï¼šNatural lighting, golden hour warmth, practical light sourcesã€‚
è‰²è°ƒï¼šè‡ªç„¶å…‰ï¼Œç•¥å¸¦æ‚ä¹±çš„ç”Ÿæ´»èƒŒæ™¯ï¼Œæ¸©æš–çœŸå®ã€‚
å‚è€ƒï¼šBrandon Li çºªå®é£æ ¼ + Casey Neistat Vlog ç¾å­¦ã€‚""",
            "shot_keywords": CINEMATIC_TEMPLATES["é£æ ¼æ»¤é•œ"]["brandon_li"],
            "default_shot": "medium_shot",
            "bgm_style": "æ¸©æš–åŸå£°å‰ä»–ï¼Œè½»å¿«é’¢ç´ï¼Œæ²»æ„ˆç³»èƒŒæ™¯Lofiï¼ˆå‚è€ƒï¼šIndie Folk é£æ ¼ï¼‰"
        },
        "ğŸ¬ POVæ²‰æµ¸æµï¼ˆç¬¬ä¸€äººç§°+ä»£å…¥æ„Ÿï¼‰": {
            "tone": "å‹è¿«æ„Ÿã€ä»£å…¥æ„Ÿã€å…±æƒ…ã€‚ç›®æ ‡ï¼šæ‰“ç ´å±å¹•éš”é˜™ã€‚è¯­è¨€ï¼šå¤§é‡ä½¿ç”¨'ä½ 'ï¼Œå¼ºè°ƒæ„Ÿå®˜ç»†èŠ‚ã€‚",
            "hook": "ç”¨å¦‚æœä½ æ˜¯...æˆ–æƒ³è±¡ä¸€ä¸‹ä½ æ­£åœ¨...ç›´æ¥æŠŠè§‚ä¼—æ‹‰å…¥åœºæ™¯",
            "visual_base": "POV æé™è¿åŠ¨ + FPS æ¸¸æˆè§†è§’ï¼Œè¶…å¹¿è§’ï¼Œæ²‰æµ¸å¼",
            "visual_rules": """è§†è§‰ï¼šFirst-person POVï¼Œimmersive perspectiveï¼Œsubjective cameraã€‚
é•œå¤´ï¼šUltra-wide angle lens, motion blur, edge distortion, POV hands in frameã€‚
å…‰å½±ï¼šMoody atmospheric lighting, practical sources, realistic ambianceã€‚
è‰²è°ƒï¼šç„¦è™‘æ„Ÿæˆ–å‹è¿«æ„Ÿæ°›å›´ï¼Œslightly desaturatedã€‚
å‚è€ƒï¼šPOV æé™è¿åŠ¨è¿é•œ + FPS æ¸¸æˆè§†è§’ + ç¬¬ä¸€äººç§°ç”µå½±ã€‚""",
            "shot_keywords": "First-person POV, Ultra-wide angle, Motion blur, Immersive perspective, Subjective camera, POV hands",
            "default_shot": "pov",
            "bgm_style": "ç´§å¼ æ‚¬ç–‘éŸ³æ•ˆï¼Œå¿ƒè·³å£°ï¼Œå‘¼å¸å£°ï¼Œç¯å¢ƒéŸ³å¢å¼ºæ²‰æµ¸æ„Ÿï¼ˆå‚è€ƒï¼šHorror Game OSTï¼‰"
        },
        "ğŸ”¥ æƒ…ç»ªå®£æ³„æµï¼ˆæè‡´åè½¬+å‘ç–¯æ–‡å­¦ï¼‰": {
            "tone": "æç«¯ã€çˆ½æ„Ÿã€å‘ç–¯æ–‡å­¦ã€‚ç›®æ ‡ï¼šæä¾›æƒ…ç»ªå‡ºå£ã€‚è¯­è¨€ï¼šæƒ…ç»ªæ³¢åŠ¨å‰§çƒˆï¼Œä½¿ç”¨å¤¸å¼ åŠ¨è¯ã€‚",
            "hook": "ç”¨æç«¯æƒ…ç»ªè¯å¼€åœºï¼ˆæˆ‘çœŸçš„å¿ äº†ï¼ç»™æˆ‘ç¬‘æ­»äº†ï¼ï¼‰ï¼Œä¸è®²é“ç†åªè®²æƒ…",
            "visual_base": "Daniel Schiffer + Edgar Wright é£æ ¼ï¼Œå¿«é—ªåˆ‡æ¢ï¼Œé«˜é¥±å’Œåº¦",
            "visual_rules": """è§†è§‰ï¼šæå…·å¼ åŠ›å’Œå‹è¿«æ„Ÿï¼Œhigh energy commercial styleã€‚
é•œå¤´ï¼šExtreme close-up (eyes/mouth), rapid zoom, shaky cam, quick cuts, Dutch anglesã€‚
å…‰å½±ï¼šHigh contrast, dramatic shadows, saturated colors, red and black paletteã€‚
è‰²è°ƒï¼šé«˜é¥±å’Œåº¦ï¼Œçº¢é»‘æ’è‰²ï¼Œæƒ…ç»ªåŒ–çš„è‰²å½©ã€‚
å‚è€ƒï¼šç”µå½±çº§çš„ç‰¹å†™å‰ªè¾‘ + Edgar Wright å¿«é€Ÿå‰ªè¾‘ + Daniel Schiffer å•†ä¸šé£æ ¼ã€‚""",
            "shot_keywords": CINEMATIC_TEMPLATES["é£æ ¼æ»¤é•œ"]["daniel_schiffer"],
            "default_shot": "extreme_close_up",
            "bgm_style": "å´©åç”µå­ä¹ï¼Œæ··æ²Œé¼“ç‚¹ï¼Œå°–å«å£°æ•ˆï¼Œæå…·çˆ†å‘åŠ›ï¼ˆå‚è€ƒï¼šTrap/Dubstep é£æ ¼ï¼‰"
        },
        "ğŸ± MemeæŠ—è±¡æµï¼ˆä½æˆæœ¬+ç—…æ¯’ä¼ æ’­ï¼‰": {
            "tone": "å¹½é»˜ã€ç—…æ¯’ã€è§£å‹ã€‚ç›®æ ‡ï¼šæä½é—¨æ§›ä¼ æ’­ã€‚è¯­è¨€ï¼šæ´—è„‘æ£—ã€é…åˆç®€å•è§†è§‰èŠ‚å¥ã€‚",
            "hook": "ç”¨ç½‘ç»œæ£—æˆ–æµè¡ŒEmojiå¼€åœºï¼Œé™ä½æ¥æ”¶é—¨æ§›",
            "visual_base": "TikTok  viral styleï¼Œæ‰å¹³åŒ–ï¼Œé«˜é¥±å’Œï¼Œè¡¨æƒ…åŒ…ç¾å­¦",
            "visual_rules": """è§†è§‰ï¼šFlat design, pop colors, centered composition, clean and brightã€‚
é•œå¤´ï¼šStatic camera, centered subject, simple background, eye-level framingã€‚
å…‰å½±ï¼šBright even lighting, minimal shadows, vibrant saturationã€‚
è‰²è°ƒï¼šæ˜äº®é€šé€ï¼Œå¤šå·´èƒºé…è‰²ï¼Œé«˜é¥±å’Œã€‚
å‚è€ƒï¼šè¡¨æƒ…åŒ…ç¾å­¦ + TikTok  viral style + ç®€æ˜“åŠ¨ç”»ã€‚""",
            "shot_keywords": "Flat design, Pop colors, Centered composition, Viral meme style, Bright lighting, High saturation",
            "default_shot": "medium_shot",
            "bgm_style": "æ´—è„‘ç¥æ›²ï¼Œé­”æ€§å¾ªç¯ï¼Œé«˜é¢‘ç”µéŸ³ï¼Œæ­é…ç‰¹æ•ˆéŸ³ï¼ˆå‚è€ƒï¼šVine/TikTok Viral Soundsï¼‰"
        }
    }
    
    # è·å–å½“å‰é£æ ¼é…ç½®
    style_config = STYLE_CONFIGS.get(style, STYLE_CONFIGS["ğŸ—¡ï¸ è®¤çŸ¥åˆºå®¢æµï¼ˆå†²å‡»åŠ›+ä¼˜è¶Šæ„Ÿï¼‰"])
    
    # 2ï¸âƒ£ VideoTaxi FSD 2.0 å¯¼æ¼”å¢å¼ºç‰ˆä¸»æ§æç¤ºè¯
    master_system_prompt = f"""ä½ æ˜¯ä¸€ä½é¡¶å°–è§†é¢‘åˆ¶ç‰‡äººï¼Œæ­£åœ¨æ‰§è¡Œã€{style}ã€‘é£æ ¼çš„ä»»åŠ¡ã€‚

ã€æ ¸å¿ƒé£æ ¼çº¦æŸã€‘ï¼š
{style_config['tone']}

ã€Hook å…¬å¼ã€‘ï¼š
{style_config['hook']}

ã€ğŸ¬ å¼ºåˆ¶è§†è§‰åˆ†é•œçº¦æŸã€‘ï¼š
å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§†è§‰è§„åˆ™ç¼–å†™ç”Ÿå›¾ Promptï¼š
{style_config['visual_rules']}

è¦æ±‚ï¼šç”Ÿæˆçš„å›¾åƒ Prompt å¿…é¡»åŒ…å«ï¼š
- é•œå¤´è§’åº¦ï¼ˆShot Typeï¼‰ï¼šå¦‚ Medium shot, Close-up, POV ç­‰
- å…‰å½±ï¼ˆLightingï¼‰ï¼šå¦‚ Cinematic lighting, Natural light, Deep shadows ç­‰
- è§†è§‰å‚è€ƒï¼š{style_config['shot_keywords']}

ã€ğŸ¬ VideoTaxi FSD 2.0 å¯¼æ¼”æŒ‡ä»¤é›†ã€‘ï¼š

**1. è§†è§‰ä¸€è‡´æ€§é”šç‚¹ (Visual Anchor)**ï¼š
åœ¨è¾“å‡ºå‰ï¼Œå¿…é¡»å…ˆå®šä¹‰ä¸€ä¸ª visual_anchorã€‚æ‰€æœ‰åˆ†é•œçš„ image_prompt æè¿°å¿…é¡»ä»¥è¯¥é”šç‚¹å¼€å¤´ï¼Œç¡®ä¿åŒä¸€è§†é¢‘é‡Œçš„äººç‰©/ä¸»ä½“ä¿æŒä¸€è‡´ã€‚
- å¦‚æœæ˜¯äººç‰©ç±»è§†é¢‘ï¼švisual_anchor = "åŒä¸€äºšæ´²å¹´è½»å¥³æ€§ï¼Œé»‘è‰²é•¿å‘ï¼Œç©¿ç™½è‰²è¡¬è¡«"
- å¦‚æœæ˜¯äº§å“ç±»è§†é¢‘ï¼švisual_anchor = "åŒä¸€æ¬¾é“¶è‰²æ— çº¿è€³æœºï¼Œæç®€è®¾è®¡"
- å¦‚æœæ˜¯åœºæ™¯ç±»è§†é¢‘ï¼švisual_anchor = "åŒä¸€é—´ç°ä»£ç®€çº¦åŠå…¬å®¤ï¼Œè½åœ°çª—"
æ‰€æœ‰ image_prompt å¿…é¡»ä»¥ visual_anchor å¼€å¤´ï¼Œç„¶åå†æè¿°å…·ä½“åŠ¨ä½œå’Œåœºæ™¯ã€‚

**2. æƒ…ç»ªåŠ¨æ€æ›²çº¿ (Emotion Arc)**ï¼š
ä¸¥ç¦å…¨ç¯‡åŒä¸€æƒ…ç»ªï¼å¿…é¡»éµå¾ª [Hook(å†·) -> Content(æ·±) -> Gold_Sentence(çˆ†)] çš„æ³¢æ®µï¼š
- ç¬¬1ä¸ªåˆ†é•œ(Hook)ï¼šæƒ…ç»ª = cold_question æˆ– sarcastic_mockï¼ˆå†·å¯åŠ¨ï¼Œåˆ¶é€ æ‚¬å¿µï¼‰
- ç¬¬2-3ä¸ªåˆ†é•œ(Content)ï¼šæƒ…ç»ª = deep_mystery æˆ– neutral_narrateï¼ˆæ·±å…¥å†…å®¹ï¼Œå»ºç«‹è®¤çŸ¥ï¼‰
- ç¬¬4-5ä¸ªåˆ†é•œ(Gold)ï¼šæƒ…ç»ª = angry_shout æˆ– excited_announce æˆ– fierce_warningï¼ˆçˆ†å‘é«˜æ½®ï¼Œæƒ…ç»ªé¡¶ç‚¹ï¼‰
- æœ€åä¸€ä¸ªåˆ†é•œ(Outro)ï¼šæƒ…ç»ª = sad_sigh æˆ– neutral_narrateï¼ˆä½™éŸµï¼Œå¼•å¯¼äº’åŠ¨ï¼‰

**3. SFX å¯¼æ¼”ä½ (Sound Effects Placeholder)**ï¼š
åœ¨ segments ä¸­æ–°å¢ sfx_label å­—æ®µï¼Œä¸ºåæœŸéŸ³æ•ˆé¢„ç•™ä½ç½®ï¼š
- [Transition]ï¼šè½¬åœºéŸ³æ•ˆï¼Œç”¨äºåˆ†é•œåˆ‡æ¢
- [Impact]ï¼šå†²å‡»éŸ³æ•ˆï¼Œç”¨äºé«˜æ½®/é‡‘å¥æ—¶åˆ»
- [Suspense]ï¼šæ‚¬ç–‘éŸ³æ•ˆï¼Œç”¨äºåˆ¶é€ ç´§å¼ æ„Ÿ
- [Glitch]ï¼šæ•…éšœéŸ³æ•ˆï¼Œç”¨äºç§‘æŠ€/åè½¬æ•ˆæœ
- [Silence]ï¼šé™éŸ³å ä½ï¼Œç”¨äºå‘¼å¸åœé¡¿
åˆ†é…ç­–ç•¥ï¼š
- Hookåˆ†é•œï¼šä½¿ç”¨ [Suspense] æˆ– [Silence] åˆ¶é€ æ‚¬å¿µ
- è½¬åœºåˆ†é•œï¼šä½¿ç”¨ [Transition] å¹³æ»‘åˆ‡æ¢
- é«˜æ½®åˆ†é•œï¼šä½¿ç”¨ [Impact] å¼ºåŒ–å†²å‡»åŠ›
- åè½¬åˆ†é•œï¼šä½¿ç”¨ [Glitch] åˆ¶é€ æ„å¤–æ„Ÿ

ã€é€šç”¨çˆ†æ¬¾æ³•åˆ™ã€‘ï¼š
1. é»„é‡‘å‰3ç§’ï¼šç›´æ¥åˆ‡å…¥å†²çªï¼Œç¦æ­¢é“ºå«
2. åŠ¨è¯ä¸ºç‹ï¼šç”¨è¡€è‚‰æ„Ÿã€åŠ¨ä½œæ„Ÿæ›¿æ¢ç©ºæ´çš„å½¢å®¹è¯
3. é’©å­åŠ å¯†ï¼šæ¯15ç§’å¿…æœ‰ä¸€ä¸ªæ–°è½¬æŠ˜æˆ–è§†è§‰æç¤º
4. çœŸå®æ€§çº¢çº¿ï¼šä¸ç¼–é€ æ•°æ®ï¼Œé€»è¾‘å¿…é¡»è‡ªæ´½

ã€ğŸ¤ TTSæƒ…ç»ªæ ‡æ³¨è§„èŒƒã€‘ï¼š
åœ¨æ¯ä¸ªnarrationä¸­ï¼Œå¿…é¡»ä¸ºå…³é”®å¥å­åŒ…è£¹SSMLæ ‡ç­¾æ¥æ§åˆ¶è¯­éŸ³æƒ…ç»ªï¼š

1. **è¯­é€Ÿ(rate)æ§åˆ¶**ï¼š
   - ç´§å¼ /å†²å‡»æ—¶ï¼š<prosody rate="fast">è¿™å°±æ˜¯çœŸç›¸</prosody>
   - å¼ºè°ƒ/æ²‰æ€æ—¶ï¼š<prosody rate="slow">ä½ çœŸçš„äº†è§£è‡ªå·±å—</prosody>
   - æ­£å¸¸é€Ÿåº¦ï¼š<prosody rate="medium">é»˜è®¤æ–‡æ¡ˆ</prosody>

2. **éŸ³è°ƒ(pitch)æ§åˆ¶**ï¼š
   - å…´å¥‹/æƒŠè®¶æ—¶ï¼š<prosody pitch="+15%">ä¸å¯èƒ½ï¼</prosody>
   - ä¸¥è‚ƒ/ä½æ²‰æ—¶ï¼š<prosody pitch="-10%">ç°å®å¾ˆæ®‹é…·</prosody>

3. **éŸ³é‡(volume)æ§åˆ¶**ï¼š
   - å¼ºè°ƒå…³é”®è¯ï¼š<prosody volume="+20%">æ ¸å¿ƒç»“è®º</prosody>
   - ä½å£°ç»†è¯­ï¼š<prosody volume="-10%">ä¸ä¸ºäººçŸ¥çš„ç§˜å¯†</prosody>

4. **ç»„åˆä½¿ç”¨**ï¼š
   <prosody rate="fast" pitch="+10%" volume="+15%">è¿™æ˜¯çˆ†ç‚¹é‡‘å¥ï¼</prosody>

ğŸ’¡ **æ ‡æ³¨ç­–ç•¥**ï¼š
- æ¯ä¸ªåˆ†é•œè‡³å°‘æ ‡æ³¨1-2å¤„æƒ…ç»ªè½¬æŠ˜ç‚¹
- Hook(å‰3ç§’)å¿…é¡»æœ‰å¼ºçƒˆçš„è¯­é€Ÿ/éŸ³è°ƒå˜åŒ–
- åè½¬/æ‚¬å¿µå¥å¿…é¡»é™é€Ÿæˆ–å˜è°ƒï¼Œå¢å¼ºå†²å‡»æ„Ÿ

ã€ğŸ” å¼ºåˆ¶è‡ªæ£€ç¯èŠ‚ã€‘ï¼š
åœ¨è¾“å‡ºJSONå‰ï¼Œä½ å¿…é¡»è¿›è¡Œå†…éƒ¨å®¡è®¡ï¼Œå¦‚æœ‰è¿åç«‹åˆ»é‡å†™ï¼š
1. **æœå¯»å¹¶åˆ é™¤**ï¼šæŸ¥æ‰¾æ˜¯å¦å­˜åœ¨"å…¶å®ã€é‚£ä¹ˆã€æ€»ä¹‹ã€è®©æˆ‘ä»¬ã€å¤§å®¶å¥½"ç­‰AIåºŸè¯ï¼Œä¸€å¾‹åˆ æ‰
2. **é”åŒ–åŠ¨è¯**ï¼šæ£€æŸ¥å‰3ç§’æ˜¯å¦æœ‰"å¾ˆã€éå¸¸ã€æ¯”è¾ƒ"ç­‰è™šè¯ï¼Œå¿…é¡»æ›¿æ¢ä¸ºå…·ä½“åŠ¨ä½œ
3. **é€»è¾‘å¯¹é½**ï¼šæ£€æŸ¥ç»“å°¾æ˜¯å¦åœ¨è®²å¤§é“ç†ï¼Œå¦‚æœæ˜¯ï¼Œå¼ºåˆ¶æ”¹ä¸ºåé—®å¥æˆ–æ‚¬å¿µé’©å­
4. **çœŸå®æ„Ÿæ£€æŸ¥**ï¼šç¡®ä¿è¯­æ°”åƒä¸ªæ´»äººï¼Œå¸¦ç‚¹æ–¹è¨€æ„Ÿæˆ–æ±Ÿæ¹–æ°”ï¼Œä¸è¦åƒAIç»™äººç§‘æ™®
5. **è§†è§‰æ£€æŸ¥**ï¼šç¡®è®¤æ¯ä¸ª image_prompt æ˜¯å¦åŒ…å«äº†é•œå¤´è§’åº¦ã€å…‰å½±å’Œè§†è§‰å‚è€ƒï¼Œå¿…é¡»ç¬¦åˆã€è§†è§‰çº¦æŸã€‘
6. **æƒ…ç»ªæ£€æŸ¥**ï¼šç¡®è®¤narrationä¸­æ˜¯å¦åŒ…å«äº†è‡³å°‘1ä¸ª<prosody>æ ‡ç­¾ï¼ŒHookå¥å¿…é¡»æœ‰æƒ…ç»ªæ ‡æ³¨

ã€ğŸ“ å‰§æœ¬å†…å®¹æ ¸å¿ƒè¦æ±‚ã€‘ï¼š
1. **å£æ’­æ–‡æ¡ˆå¿…é¡»ç´§æ‰£ä¸»é¢˜**ï¼šæ¯ä¸€å¥éƒ½è¦å›´ç»•"{topic}"å±•å¼€ï¼Œç¦æ­¢åç¦»ä¸»é¢˜çš„æ³›æ³›è€Œè°ˆ
2. **emotion_vibe å¿…é¡»åŒ¹é…å†…å®¹æƒ…ç»ª**ï¼šæ–‡æ¡ˆæ˜¯ä»€ä¹ˆæƒ…ç»ªï¼Œå°±æ ‡æ³¨ä»€ä¹ˆæ ‡ç­¾ï¼Œä¸èƒ½ä¸ºäº†å‡‘æ›²çº¿è€Œç¡¬è´´æ ‡ç­¾
3. **ç”»é¢æç¤ºè¯å¿…é¡»å‘¼åº”æ–‡æ¡ˆ**ï¼šçœ‹åˆ°ç”»é¢å°±èƒ½æƒ³åˆ°æ–‡æ¡ˆï¼Œçœ‹åˆ°æ–‡æ¡ˆå°±èƒ½æƒ³è±¡ç”»é¢
4. **sfx_label å¿…é¡»æœåŠ¡æƒ…ç»ª**ï¼šéŸ³æ•ˆæ˜¯ä¸ºäº†å¼ºåŒ–å½“å‰æƒ…ç»ªï¼Œä¸æ˜¯ä¸ºäº†å¡«æ»¡å­—æ®µ

ã€ğŸ¬ Visual Anchor ä½¿ç”¨è§„èŒƒã€‘ï¼š
- visual_anchor åªå®šä¹‰ä¸€æ¬¡ï¼ŒåŒ…å«ä¸»è§’çš„æ ¸å¿ƒç‰¹å¾ï¼ˆå¤–è²Œ+æœè£…+æ°”è´¨ï¼‰
- æ¯ä¸ªåˆ†é•œçš„ image_prompt **åªå†™åœºæ™¯å’ŒåŠ¨ä½œ**ï¼Œä¸è¦é‡å¤å†™ä¸»è§’å¤–è²Œ
- ç¤ºä¾‹ï¼š
  - visual_anchor: "A 30-year-old Asian woman with short black hair, wearing a red blazer, confident expression"
  - åˆ†é•œ1 image_prompt: "sitting at desk, typing on laptop, office background"
  - åˆ†é•œ2 image_prompt: "standing by window, looking at city skyline, sunset lighting"
  - âŒ é”™è¯¯ï¼šæ¯ä¸ªåˆ†é•œéƒ½é‡å¤"A 30-year-old Asian woman with short black hair..."

ã€â±ï¸ æ—¶é—´è½´è§„èŒƒã€‘ï¼š
- æ¯ä¸ªåˆ†é•œ **2-4ç§’**ï¼Œå¿«èŠ‚å¥çŸ­å¹³å¿«
- æ€»æ—¶é•¿æ§åˆ¶åœ¨ **15-25ç§’**ï¼ˆæŠ–éŸ³é»„é‡‘æ—¶é•¿ï¼‰
- æ—¶é—´å¿…é¡»è¿ç»­ï¼š0-3, 3-6, 6-9, 9-12, 12-15...

ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
å¿…é¡»ä¸¥æ ¼è¾“å‡ºJSONå¯¹è±¡ï¼ŒåŒ…å« visual_anchor å’Œ segments æ•°ç»„ã€‚æ ¼å¼ï¼š
{{
  "visual_anchor": "ä¸»è§’ç‰¹å¾æè¿°ï¼ˆè‹±æ–‡ï¼Œåªå†™ä¸€æ¬¡ï¼‰",
  "segments": [
    {{
      "start_time": 0,
      "end_time": 3,
      "narration": "ç´§æ‰£ä¸»é¢˜çš„å£æ’­æ–‡æ¡ˆï¼ˆå¸¦SSMLæ ‡ç­¾ï¼‰", 
      "emotion_vibe": "æ ¹æ®æ–‡æ¡ˆå®é™…æƒ…ç»ªé€‰æ‹©",
      "image_prompt": "åœºæ™¯+åŠ¨ä½œæè¿°ï¼ˆè‹±æ–‡ï¼Œä¸åŒ…å«ä¸»è§’å¤–è²Œï¼‰",
      "sfx_label": "æœåŠ¡å½“å‰æƒ…ç»ªçš„éŸ³æ•ˆ"
    }}
  ]
}}

âš¡ **å…³é”®æ£€æŸ¥ç‚¹**ï¼š
- [ ] visual_anchor æ˜¯å¦ç²¾ç¡®å®šä¹‰äº†ä¸»è§’ç‰¹å¾ï¼Ÿ
- [ ] image_prompt æ˜¯å¦**æ²¡æœ‰é‡å¤**ä¸»è§’å¤–è²Œæè¿°ï¼Ÿ
- [ ] æ¯ä¸ªåˆ†é•œçš„ narration æ˜¯å¦éƒ½ç´§æ‰£"{topic}"ï¼Ÿ
- [ ] emotion_vibe æ˜¯å¦ä¸æ–‡æ¡ˆæƒ…ç»ªçœŸæ­£åŒ¹é…ï¼Ÿ
- [ ] æ—¶é—´è½´æ˜¯å¦ç´§å‡‘ï¼ˆ2-4ç§’/åˆ†é•œï¼‰ï¼Ÿ

ç»å¯¹ä¸è¦è¾“å‡ºMarkdownæ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰æˆ–å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚"""
    
    # 3ï¸âƒ£ è°ƒç”¨AIæ¨¡å‹
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": master_system_prompt},
                {"role": "user", "content": f"ä¸»é¢˜ï¼š{topic}"}
            ],
            temperature=0.7,
            response_format={'type': 'json_object'}
        )
        
        content = response.choices[0].message.content
        clean_content = re.sub(r'```json\n|\n```|```', '', content).strip()
        result = json.loads(clean_content)
        
        # ğŸ¬ VideoTaxi FSD 2.0: è§£ææ–°çš„ JSON ç»“æ„
        if isinstance(result, dict):
            # æ–°æ ¼å¼ï¼šåŒ…å« visual_anchor å’Œ segments
            if 'segments' in result and isinstance(result['segments'], list):
                visual_anchor = result.get('visual_anchor', '')
                segments = result['segments']
                # å°† visual_anchor æ³¨å…¥åˆ°æ¯ä¸ª segment ä¸­ä¾›åç»­ä½¿ç”¨
                for seg in segments:
                    seg['_visual_anchor'] = visual_anchor
                st.success(f"âœ… {style} å‰§æœ¬å·²é€šè¿‡ VideoTaxi FSD 2.0 å¯¼æ¼”å®¡è®¡ï¼")
                return segments
            # å…¼å®¹æ—§æ ¼å¼ï¼šç›´æ¥è¿”å›æ•°ç»„
            for v in result.values():
                if isinstance(v, list):
                    st.success(f"âœ… {style} å‰§æœ¬å·²é€šè¿‡è‡ªæ£€å®¡è®¡ï¼")
                    return v
        
        st.success(f"âœ… {style} å‰§æœ¬å·²é€šè¿‡è‡ªæ£€å®¡è®¡ï¼")
        return result if isinstance(result, list) else []
        
    except Exception as e:
        st.error(f"{style} å‰§æœ¬ç”Ÿæˆå¤±è´¥: {e}")
        return []

def generate_images_zhipu(scenes_data, api_key, style_config=None):
    """
    ğŸ¬ è°ƒç”¨æ™ºè°± CogView-3-Plus - VideoTaxi Cinematography v3.0 å¯¼æ¼”å®šç„¦ç‰ˆ
    
    æ ¸å¿ƒå‡çº§ï¼š
    1. ä½¿ç”¨ build_master_image_prompt æ„å»ºç”µå½±çº§ Prompt
    2. è§†è§‰é”šç‚¹ç¡®ä¿äººç‰©ä¸€è‡´æ€§
    3. å¼ºåˆ¶é•œå¤´è¯­è¨€ã€å…‰å½±ã€é£æ ¼æ»¤é•œ
    """
    url = "https://open.bigmodel.cn/api/paas/v4/images/generations".strip()
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
    image_paths = []
    
    # è·å–è§†è§‰é”šç‚¹ï¼ˆä»ç¬¬ä¸€ä¸ª scene ä¸­è·å–ï¼‰
    visual_anchor = ""
    if scenes_data and len(scenes_data) > 0:
        visual_anchor = scenes_data[0].get('_visual_anchor', '')
    
    # é»˜è®¤é£æ ¼é…ç½®
    default_style = {
        "shot_keywords": CINEMATIC_TEMPLATES["é£æ ¼æ»¤é•œ"]["sam_kolder"],
        "default_shot": "close_up"
    }
    style = style_config or default_style
    
    for i, scene in enumerate(scenes_data):
        # ğŸ” æ£€æŸ¥ image_prompt æ˜¯å¦ä¸ºç©º
        raw_prompt = scene.get('image_prompt', '')
        if not raw_prompt or raw_prompt.strip() == "":
            st.warning(f"âš ï¸ åˆ†é•œ {i+1} çš„ image_prompt ä¸ºç©ºï¼Œè·³è¿‡å›¾ç‰‡ç”Ÿæˆ")
            image_paths.append(None)
            continue
        
        # ğŸ¬ ä½¿ç”¨å¯¼æ¼”çº§ Prompt æ„å»ºå™¨
        # æå–åœºæ™¯æè¿°ï¼ˆå»æ‰å¯èƒ½çš„ visual_anchor å‰ç¼€ï¼‰
        scene_desc = raw_prompt
        if visual_anchor and raw_prompt.startswith(visual_anchor):
            scene_desc = raw_prompt[len(visual_anchor):].strip(", ")
        
        # æ ¹æ®åˆ†é•œä½ç½®é€‰æ‹©é•œå¤´ç±»å‹
        shot_type = style.get('default_shot', 'close_up')
        if i == 0:
            shot_type = 'extreme_close_up'  # Hook ç”¨ç‰¹å†™
        elif i == len(scenes_data) - 1:
            shot_type = 'wide_shot'  # ç»“å°¾ç”¨è¿œæ™¯
        
        # æ„å»ºå¤§å¸ˆçº§ Prompt
        enhanced_prompt = build_master_image_prompt(
            visual_anchor=visual_anchor,
            scene_description=scene_desc,
            style_config=style,
            shot_type=shot_type
        )
            
        # ç¡®ä¿æç¤ºè¯é•¿åº¦åˆé€‚ï¼ˆæ™ºè°±æœ‰é•¿åº¦é™åˆ¶ï¼‰
        if len(enhanced_prompt) > 500:
            enhanced_prompt = enhanced_prompt[:497] + "..."
            
        payload = {
            "model": "cogview-3-plus", 
            "prompt": enhanced_prompt, 
            "size": "1024x1920"
        }
        
        st.toast(f"ğŸ¨ æ­£åœ¨ç»˜åˆ¶åˆ†é•œ {i+1}/{len(scenes_data)} ...")
        st.caption(f"ğŸ“ ä¼˜åŒ–åæç¤ºè¯: {enhanced_prompt[:80]}...")
        
        try:
            res = requests.post(url, json=payload, headers=headers, timeout=60).json()
            
            # ğŸ” è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
            if 'data' in res:
                img_url = res['data'][0]['url']
                temp_name = f"temp_scene_{i}.jpg"
                st.write(f"âœ… åˆ†é•œ {i+1} å›¾ç‰‡URLè·å–æˆåŠŸ: {img_url[:50]}...")
                urllib.request.urlretrieve(img_url, temp_name)
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦ä¸‹è½½æˆåŠŸ
                if os.path.exists(temp_name) and os.path.getsize(temp_name) > 0:
                    st.write(f"âœ… åˆ†é•œ {i+1} å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {temp_name} ({os.path.getsize(temp_name)} bytes)")
                    image_paths.append(temp_name)
                else:
                    st.error(f"âŒ åˆ†é•œ {i+1} å›¾ç‰‡ä¸‹è½½å¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©º")
                    image_paths.append(None)
            else:
                st.error(f"âŒ åˆ†é•œ {i+1} æ™ºè°±APIè¿”å›é”™è¯¯: {res}")
                image_paths.append(None)
        except Exception as e:
            st.error(f"âŒ åˆ†é•œ {i+1} å›¾ç‰‡ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            image_paths.append(None)
    return image_paths

def get_pexels_videos(query, api_key, required_duration):
    """Pexels API çœŸå®ç´ æå…œåº•"""
    url = "https://api.pexels.com/videos/search".strip()
    headers = {"Authorization": api_key}
    params = {"query": query, "per_page": 5, "orientation": "portrait"}
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        data = response.json()
        if not data.get('videos'):
            params['query'] = "nature landscape"  # è‹±æ–‡é£æ™¯ä¿åº•
            response = requests.get(url, headers=headers, params=params, timeout=10)
            data = response.json()

        downloaded_files = []
        current_dur = 0.0
        from moviepy.editor import VideoFileClip
        
        for i, video in enumerate(data.get('videos', [])):
            if current_dur >= required_duration:
                break
            video_files = video.get('video_files', [])
            hd_file = next((f for f in video_files if f['quality'] == 'hd'), video_files[0])
            link = hd_file['link']
            
            temp_name = f"temp_pexels_{i}.mp4"
            urllib.request.urlretrieve(link, temp_name)
            
            clip = VideoFileClip(temp_name)
            current_dur += clip.duration
            clip.close()
            downloaded_files.append(temp_name)
            
        return downloaded_files
    except Exception as e:
        st.error(f"Pexelsç´ æè·å–å¤±è´¥ï¼š{e}")
        return []

def refine_script_data(current_scenes, api_key):
    """âœ¨ è°ƒç”¨å¤§å¸ˆè¿›è¡ŒäºŒæ¬¡ç²¾ä¿®ï¼ŒæŒ‘åˆºå¹¶æå‡æ–‡æ¡ˆèƒ½é‡å¯†åº¦"""
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1".strip())
    
    # å°†å½“å‰çš„å‰§æœ¬è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²å–‚ç»™ AI
    current_json_str = json.dumps(current_scenes, ensure_ascii=False)
    
    refine_system_prompt = """ä½ æ˜¯å…¨ç½‘æœ€æ¯’èˆŒã€æœ€æ‡‚äººæ€§çš„çŸ­è§†é¢‘å†…å®¹æ€»ç›‘ã€‚ä½ æ·±è°™â€œè®¤çŸ¥åˆºå®¢â€çˆ†æ¬¾æ³•åˆ™ï¼Œä½†åŒæ—¶åšå®ˆå†…å®¹çš„çœŸå®æ€§å’Œå‡†ç¡®æ€§ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ï¼šæ— æƒ…åœ°å®¡æŸ¥å¹¶ç²¾ä¿®ç”¨æˆ·æäº¤çš„åˆ†é•œå‰§æœ¬ï¼Œæå‡å…¶æˆä¸ºçˆ†æ¬¾çš„æ¦‚ç‡ï¼ŒåŒæ—¶ç¡®ä¿å†…å®¹å¯ä¿¡ã€‚

ã€ä½ çš„æ¯’èˆŒå®¡æŸ¥æ¸…å•ä¸ä¿®æ”¹è§„åˆ™ã€‘ï¼š
1. é»„é‡‘å‰3ç§’Hookæ£€æŸ¥ï¼šç¬¬ä¸€å¥å¦‚æœå¹³æ·¡æ— å¥‡ï¼Œç«‹åˆ»æŠŠå®ƒæ”¹æˆå¸¦æœ‰å¼ºå†²çªã€å¼ºæ‚¬å¿µã€åå¸¸è¯†çš„çˆ†ç‚¹é‡‘å¥ï¼
2. åºŸè¯å¤§æ‰«é™¤ï¼šæŠŠæ‰€æœ‰çš„â€œé‚£ä¹ˆã€å…¶å®ã€ä¼—æ‰€å‘¨çŸ¥ã€æ¥ä¸‹æ¥â€ç­‰è¿æ¥è¯å…¨éƒ¨åˆ æ‰ï¼ä¸€å¥åºŸè¯éƒ½ä¸è¦ç•™ã€‚
3. è½¯å¼±è¯æ±‡å‡ç»´ï¼šæŠŠæ‰€æœ‰çš„å½¢å®¹è¯ï¼ˆå¾ˆç”Ÿæ°”ã€å¾ˆå¿«ã€å¾ˆå¥½ï¼‰æ”¹æˆå…·ä½“ã€æœ‰å†²å‡»åŠ›çš„åŠ¨è¯å’Œåè¯æ­é…ï¼ˆå¦‚ï¼šæŠŠæ‰‹æœºç ¸çƒ‚ã€æ¨èƒŒæ„Ÿã€åŠæ‰“åŒè¡Œï¼‰ã€‚
4. é’©å­å¯†åº¦æ£€æŸ¥ï¼šç¡®ä¿æ¯æ®µæ–‡æ¡ˆéƒ½æœ‰æƒ…ç»ªèµ·ä¼ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå¼ºè¡ŒåŠ å…¥åé—®æˆ–é¢„å‘Šã€‚
5. ç”»é¢å¼ åŠ›æå‡ï¼šæ£€æŸ¥ image_prompt æ˜¯å¦è¶³å¤Ÿæœ‰è¡¨ç°åŠ›ï¼Œé€‚å½“å¢åŠ å¤§å¸ˆçº§æ‘„å½±é£æ ¼ï¼ˆå¦‚ï¼šSam Kolder style, cinematic lighting, extreme close-upï¼‰ä»¥å¢å¼ºç”»é¢è´¨æ„Ÿã€‚

ã€â— å…³é”®åŸåˆ™ï¼šçœŸå®æ€§ä¸å‡†ç¡®æ€§å®¡æŸ¥ã€‘ï¼š
6. **äº‹å®æ ¸æŸ¥**ï¼šå¦‚æœæ–‡æ¡ˆæ¶‰åŠæ•°æ®ã€ç»Ÿè®¡ã€å†å²äº‹ä»¶ã€ç§‘å­¦çŸ¥è¯†ï¼Œå¿…é¡»ä¿æŒè°¨æ…å’Œå‡†ç¡®ã€‚ä¸è¦ç¼–é€ æ•°æ®æˆ–å¤¹å¤§äº‹å®ã€‚
7. **é€»è¾‘è‡ªæ´½**ï¼šç¡®ä¿æ–‡æ¡ˆé€»è¾‘è¿è´¯ï¼Œä¸èƒ½ä¸ºäº†åˆºæ¿€æ•ˆæœè€Œå‡ºç°è‡ªç›¸çŸ›ç›¾æˆ–æ˜æ˜¾é”™è¯¯çš„å› æœå…³ç³»ã€‚
8. **é¿å…è¯¯å¯¼**ï¼šä¸è¦ä½¿ç”¨å¼•å¯¼æ€§æˆ–è¯¯å¯¼æ€§çš„æ ‡é¢˜å…šè¯­æ±‰ï¼Œå³ä½¿å®ƒä»¬å¾ˆå¸å¼•äººã€‚çˆ†æ¬¾ä¸ç­‰äºè™šå‡ã€‚
9. **å°Šé‡å¸¸è¯†**ï¼šå¯¹äºå¸¸è¯†æ€§å†…å®¹ï¼Œä¸è¦ä¸ºäº†â€œåå¸¸è¯†â€æ•ˆæœè€Œæ‰°ä¹±åŸºæœ¬äº‹å®ã€‚
10. **å¯éªŒè¯æ€§**ï¼šå¦‚æœæåˆ°å…·ä½“çš„äº§å“ã€å“ç‰Œã€äº‹ä»¶ï¼Œç¡®ä¿å®ƒä»¬æ˜¯çœŸå®å­˜åœ¨çš„ï¼Œå¯ä»¥è¢«æŸ¥è¯çš„ã€‚

ã€å¹³è¡¡è‰ºæœ¯ã€‘ï¼š
- åœ¨æå‡æ–‡æ¡ˆå¸å¼•åŠ›çš„åŒæ—¶ï¼Œç»ä¸ç‰ºç‰²å†…å®¹çš„çœŸå®æ€§
- ç”¨çœŸå®çš„æ•…äº‹ã€çœŸå®çš„æ•°æ®ã€çœŸå®çš„æƒ…æ„Ÿæ‰“åŠ¨äººï¼Œè€Œä¸æ˜¯ç¼–é€ 
- â€œè®¤çŸ¥åˆºå®¢â€çš„æ ¸å¿ƒæ˜¯åˆºç—›ç‚¹ï¼Œä¸æ˜¯é€ è°£

ã€å¼ºåˆ¶è¾“å‡ºæ ¼å¼ã€‘
ç›´æ¥è¾“å‡ºä¿®æ”¹åçš„çº¯ JSON æ•°ç»„ï¼Œä¿æŒåŸæœ‰ç»“æ„ä¸å˜ï¼Œç»å¯¹ä¸è¦è¾“å‡ºä»»ä½• markdown ç¬¦å·ï¼ˆå¦‚ ```jsonï¼‰å’Œè§£é‡Šæ€§æ–‡å­—ï¼š
[{"narration": "ç²¾ä¿®åçš„åˆºå®¢æ–‡æ¡ˆï¼ˆçœŸå®ä¸”æœ‰åŠ›ï¼‰", "image_prompt": "ç²¾ä¿®åçš„ç”»é¢æç¤ºè¯"}]"""

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": refine_system_prompt},
                {"role": "user", "content": f"è¯·ç«‹åˆ»æ¯’èˆŒæ‰¹æ”¹å¹¶é‡å†™ä»¥ä¸‹å‰§æœ¬ï¼Œç›´æ¥è¿”å›ç²¾ä¿®åçš„ JSON æ•°ç»„ï¼š\n\n{current_json_str}"}
            ],
            temperature=0.6, # ç²¾ä¿®æ¨¡å¼ä¸‹é™ä½ä¸€ç‚¹æ¸©åº¦ï¼Œä¿è¯ç»“æ„ç¨³å®šå’Œä¿®æ”¹çš„ç²¾å‡†åº¦
            response_format={'type': 'json_object'}
        )
        
        content = response.choices[0].message.content
        clean_content = re.sub(r'```json\n|\n```|```', '', content).strip()
        refined_scenes = json.loads(clean_content)
        
        if isinstance(refined_scenes, dict):
            for v in refined_scenes.values():
                if isinstance(v, list): return v
        return refined_scenes if isinstance(refined_scenes, list) else []
        
    except Exception as e:
        st.error(f"å¤§å¸ˆç²¾ä¿®å¤±è´¥: {e}")
        return []

def refine_script_by_chat(current_scenes, user_request, api_key):
    """ğŸ’¬ å¯¹è¯å¾®è°ƒï¼šæ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œæ™ºèƒ½ä¿®æ”¹å‰§æœ¬
    
    Args:
        current_scenes: å½“å‰å‰§æœ¬çš„ scenes_data
        user_request: ç”¨æˆ·çš„ä¿®æ”¹éœ€æ±‚(å¦‚"ç¬¬äºŒæ®µå¤ªå¹³æ·¡äº†ï¼ŒåŠ ç‚¹åè½¬")
        api_key: DeepSeek API Key
    
    Returns:
        ä¿®æ”¹åçš„ scenes_data
    """
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1".strip())
    
    # æ„é€  Promptï¼šä¼ é€’å½“å‰å‰§æœ¬ + ç”¨æˆ·æ„å›¾
    system_prompt = """ä½ æ˜¯ä¸€ä½ç²¾é€šçŸ­è§†é¢‘å¯¼æ¼”çš„ AI åŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç»™ä½ ä¸€ä¸ªå·²å­˜åœ¨çš„å‰§æœ¬ï¼Œå¹¶æå‡ºä¿®æ”¹éœ€æ±‚ã€‚

ã€ä½ çš„ä»»åŠ¡ã€‘ï¼š
1. ç†è§£ç”¨æˆ·çš„æ„å›¾(å¦‚"åŠ ç‚¹åè½¬"ã€"ç¼©çŸ­æ—¶é•¿"ã€"æ›´æœ‰å†²å‡»åŠ›"ç­‰)
2. åªä¿®æ”¹ç›¸å…³éƒ¨åˆ†ï¼Œä¿æŒå…¶ä»–å†…å®¹ä¸å˜
3. ä¿æŒåŸæœ‰çš„çˆ†æ¬¾åŸºå› (é»„é‡‘å‰3ç§’ã€é«˜å¯†åº¦é’©å­ã€å…·ä½“åŒ–è¡¨è¾¾)
4. ä¿æŒ image_prompt çš„è§†è§‰é£æ ¼ä¸€è‡´æ€§

ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
ä¸¥æ ¼è¾“å‡º JSON æ•°ç»„ï¼Œæ ¼å¼ï¼š
[{"narration": "å£æ’­æ–‡æ¡ˆ", "image_prompt": "English prompt, cinematic style"}]

ç»å¯¹ä¸è¦è¾“å‡º Markdown æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰æˆ–å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚"""
    
    try:
        # æ„é€ ç”¨æˆ·æ¶ˆæ¯
        user_message = f"""å½“å‰å‰§æœ¬ï¼š
{json.dumps(current_scenes, ensure_ascii=False, indent=2)}

ç”¨æˆ·è¯´ï¼š{user_request}

è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ä¿®æ”¹å‰§æœ¬ï¼Œè¿”å›å®Œæ•´çš„ JSON æ•°ç»„ã€‚"""
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.7,
            response_format={'type': 'json_object'}
        )
        
        content = response.choices[0].message.content
        clean_content = re.sub(r'```json\n|\n```|```', '', content).strip()
        refined_scenes = json.loads(clean_content)
        
        # å¤„ç†å¯èƒ½çš„åµŒå¥—ç»“æ„
        if isinstance(refined_scenes, dict):
            for v in refined_scenes.values():
                if isinstance(v, list): return v
        return refined_scenes if isinstance(refined_scenes, list) else []
        
    except Exception as e:
        st.error(f"å¯¹è¯å¾®è°ƒå¤±è´¥: {e}")
        return []
