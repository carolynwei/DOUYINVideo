import os
import platform
import asyncio
import edge_tts
import streamlit as st
from moviepy.editor import AudioFileClip, ImageClip, TextClip, CompositeVideoClip, concatenate_videoclips, CompositeAudioClip

# ğŸ”‘ ç¯å¢ƒè‡ªé€‚åº”é…ç½®ï¼šè‡ªåŠ¨è¯†åˆ« Linux äº‘ç«¯æˆ– Windows æœ¬åœ°
if platform.system() == "Linux":
    os.environ["IMAGEMAGICK_BINARY"] = "/usr/bin/convert"  # äº‘ç«¯è·¯å¾„
else:
    # è¿™é‡Œçš„è·¯å¾„éœ€ä¸ä½ æœ¬åœ°å®‰è£…è·¯å¾„ä¸€è‡´
    os.environ["IMAGEMAGICK_BINARY"] = r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe"

async def text_to_mp3(text, filename):
    """ã€äº‘ç«¯ä¼˜åŒ–ç‰ˆã€‘ç›´æ¥è”ç½‘ç”Ÿæˆé…éŸ³ï¼Œå¢åŠ é‡è¯•é€»è¾‘"""
    for attempt in range(3):
        try:
            # åˆ é™¤äº† proxy å‚æ•°ï¼Œäº‘ç«¯ç›´è¿é€Ÿåº¦æå¿«
            communicate = edge_tts.Communicate(text, "zh-CN-YunxiNeural", rate="+10%")
            await communicate.save(filename)
            return True
        except Exception as e:
            print(f"TTS å°è¯• {attempt+1}/3 å¤±è´¥: {e}")
            await asyncio.sleep(2)
    return False

def generate_all_audios_sync(scenes_data):
    """ä¸²è¡Œç”Ÿæˆæ‰€æœ‰åˆ†é•œé…éŸ³"""
    audio_files = []
    for i, scene in enumerate(scenes_data):
        audio_file = f"temp_audio_{i}.mp3"
        st.toast(f"ğŸ™ï¸ AI é…éŸ³ç”Ÿæˆä¸­... {i+1}/{len(scenes_data)}")
        if asyncio.run(text_to_mp3(scene['narration'], audio_file)):
            audio_files.append(audio_file)
        else:
            # å¤±è´¥å…œåº•é€»è¾‘
            audio_files.append(None)
        asyncio.run(asyncio.sleep(0.5))
    return audio_files

def render_ai_video_pipeline(scenes_data, zhipu_key, output_path, pexels_key=None):
    """æ ¸å¿ƒè§†é¢‘æ¸²æŸ“ç®¡çº¿"""
    from api_services import generate_images_zhipu
    
    # 1. èµ„æºç”Ÿæˆ
    image_paths = generate_images_zhipu(scenes_data, zhipu_key)
    audio_files = generate_all_audios_sync(scenes_data)
    
    scene_clips = []
    temp_files = []

    # 2. é€åˆ†é•œåˆæˆ
    for i, scene in enumerate(scenes_data):
        if not audio_files[i]: continue
            
        audio_clip = AudioFileClip(audio_files[i])
        dur = audio_clip.duration
        temp_files.append(audio_files[i])
        
        # ç”»é¢é€»è¾‘ï¼šAIç»˜ç”» > é»‘å±å ä½
        if image_paths[i]:
            bg = ImageClip(image_paths[i]).set_duration(dur).resize(height=1920).crop(x_center=1080/2, width=1080)
            temp_files.append(image_paths[i])
        else:
            bg = ImageClip("black", duration=dur).resize((1080, 1920))

        # å­—å¹•é€»è¾‘
        txt = TextClip(scene['narration'], fontsize=70, color='white', font='SimHei',
                       method='caption', size=(900, None), stroke_color='black', stroke_width=2)
        txt = txt.set_duration(dur).set_position(('center', 0.8), relative=True)
        
        scene_clips.append(CompositeVideoClip([bg, txt]).set_audio(audio_clip))

    # 3. æœ€ç»ˆå‹åˆ¶ä¸ BGM æ··éŸ³
    if not scene_clips: return False
    
    final = concatenate_videoclips(scene_clips, method="compose")
    
    if os.path.exists("bgm.mp3"):
        bgm = AudioFileClip("bgm.mp3").volumex(0.08).set_duration(final.duration)
        final = final.set_audio(CompositeAudioClip([final.audio, bgm]))

    # 4. å¯¼å‡º (ä¼˜åŒ–å‚æ•°é˜²æ­¢äº‘ç«¯å†…å­˜æº¢å‡º)
    final.write_videofile(output_path, fps=24, codec="libx264", audio_codec="aac", 
                          threads=4, preset="ultrafast", logger=None)
    
    # 5. èµ„æºæ¸…ç†
    final.close()
    for f in temp_files:
        if f and os.path.exists(f): 
            try: os.remove(f)
            except: pass
    return True
