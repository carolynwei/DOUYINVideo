import os
import platform
import asyncio
import edge_tts
import numpy as np
import requests
import json
import base64
import uuid
import subprocess
import sys
from PIL import Image, ImageDraw, ImageFont
import streamlit as st
from moviepy.editor import AudioFileClip, ImageClip, ColorClip, CompositeVideoClip, concatenate_videoclips, CompositeAudioClip

# ðŸ”‘ å­—ä½“è·¯å¾„é…ç½®ï¼šå¤šçº§é™çº§ç­–ç•¥ç¡®ä¿100%å¯ç”¨
def get_font_path():
    """æ™ºèƒ½æ£€æµ‹å¯ç”¨çš„ä¸­æ–‡å­—ä½“è·¯å¾„"""
    # 1. ä¼˜å…ˆï¼šä»“åº“ä¸­çš„å­—ä½“æ–‡ä»¶ï¼ˆç»å¯¹è·¯å¾„ï¼‰
    repo_font = os.path.join(os.path.dirname(__file__), "font.ttf")
    if os.path.exists(repo_font):
        return repo_font
    
    # 2. é™çº§ï¼šå½“å‰å·¥ä½œç›®å½•çš„å­—ä½“æ–‡ä»¶
    if os.path.exists("font.ttf"):
        return os.path.abspath("font.ttf")
    
    # 3. æœ€ç»ˆé™çº§ï¼šå¯»æ‰¾ç³»ç»Ÿå­—ä½“æ–‡ä»¶
    if platform.system() == "Linux":
        linux_fonts = [
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
        ]
        for font in linux_fonts:
            if os.path.exists(font):
                return font
    
    # å¦‚æžœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›ž Noneï¼ˆåŽç»­ä¼šæœ‰é”™è¯¯æç¤ºï¼‰
    return None

FONT_PATH = get_font_path()

# ðŸ” è°ƒè¯•ä¿¡æ¯ï¼šåœ¨ Streamlit ä¾§è¾¹æ æ˜¾ç¤ºå­—ä½“è·¯å¾„
try:
    if st and hasattr(st, 'sidebar'):
        with st.sidebar:
            if FONT_PATH:
                st.success(f"âœ… å­—ä½“åŠ è½½æˆåŠŸ: {os.path.basename(FONT_PATH)}")
            else:
                st.error("âŒ æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ï¼è¯·ä¸Šä¼  font.ttf")
except:
    pass  # éž Streamlit çŽ¯å¢ƒä¸‹å¿½ç•¥

def create_subtitle_image(text, width=1080, height=400, fontsize=70):
    """ðŸŽ¨ ç”¨ Pillow æ‰‹å·¥ç»˜åˆ¶å­—å¹•å›¾ç‰‡ï¼ˆå½»åº•ç»•è¿‡ ImageMagickï¼‰"""
    if not FONT_PATH:
        raise FileNotFoundError("æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ï¼è¯·ç¡®ä¿ font.ttf å­˜åœ¨äºŽä»“åº“æ ¹ç›®å½•")
    
    # åˆ›å»ºé€æ˜ŽèƒŒæ™¯å›¾ç‰‡
    img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # åŠ è½½å­—ä½“
    try:
        font = ImageFont.truetype(FONT_PATH, fontsize)
    except Exception as e:
        st.error(f"å­—ä½“åŠ è½½å¤±è´¥: {e}")
        raise
    
    # æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œ
    lines = []
    words = text
    max_width = width - 100  # å·¦å³è¾¹è·50px
    
    # ç®€å•æ¢è¡Œé€»è¾‘ï¼šæŒ‰å­—ç¬¦å®½åº¦åˆ‡åˆ†
    current_line = ""
    for char in words:
        test_line = current_line + char
        bbox = draw.textbbox((0, 0), test_line, font=font)
        if bbox[2] - bbox[0] > max_width and current_line:
            lines.append(current_line)
            current_line = char
        else:
            current_line = test_line
    if current_line:
        lines.append(current_line)
    
    # è®¡ç®—æ€»é«˜åº¦å¹¶å±…ä¸­
    line_height = fontsize + 20
    total_height = len(lines) * line_height
    start_y = (height - total_height) // 2
    
    # ç»˜åˆ¶æ¯è¡Œæ–‡å­—ï¼ˆå…ˆç”»é»‘è¾¹ï¼Œå†ç”»ç™½å­—ï¼‰
    for i, line in enumerate(lines):
        bbox = draw.textbbox((0, 0), line, font=font)
        text_width = bbox[2] - bbox[0]
        x = (width - text_width) // 2
        y = start_y + i * line_height
        
        # é»‘è‰²æè¾¹ï¼ˆstrokeæ•ˆæžœï¼‰
        for offset_x in [-2, 0, 2]:
            for offset_y in [-2, 0, 2]:
                if offset_x != 0 or offset_y != 0:
                    draw.text((x + offset_x, y + offset_y), line, font=font, fill=(0, 0, 0, 255))
        
        # ç™½è‰²ä¸»æ–‡å­—
        draw.text((x, y), line, font=font, fill=(255, 255, 255, 255))
    
    # è½¬ä¸º numpy æ•°ç»„ä¾› MoviePy ä½¿ç”¨
    return np.array(img)

def call_volcengine_tts(text, voice_id, output_path):
    """
    é€šè¿‡è°ƒç”¨å®˜æ–¹ V3 bidirection.py è„šæœ¬æ¥ç”Ÿæˆè±†åŒ…å¤§æ¨¡åž‹éŸ³é¢‘
    æ”¯æŒ WebSocket æµå¼ä¼ è¾“ï¼Œé€‚ç”¨äºŽè±†åŒ…è¯­éŸ³åˆæˆæ¨¡åž‹ 2.0
    """
    try:
        # 1. å®‰å…¨èŽ·å–é‰´æƒä¿¡æ¯
        appid = st.secrets.get("VOLC_APPID", "")
        access_token = st.secrets.get("VOLC_ACCESS_TOKEN", "")
        
        if not appid or not access_token:
            # å¦‚æžœæ²¡æœ‰é…ç½®ç«å±±å¼•æ“Žï¼Œå›žé€€åˆ° Edge TTS
            return False
        
        # 2. å®˜æ–¹è„šæœ¬è·¯å¾„
        script_path = os.path.join(os.path.dirname(__file__), "examples", "volcengine", "bidirection.py")
        
        if not os.path.exists(script_path):
            print(f"âŒ æ‰¾ä¸åˆ°ç«å±±å¼•æ“Ž V3 è„šæœ¬: {script_path}")
            return False
        
        print(f"ðŸš€ æ­£åœ¨è°ƒç”¨è±†åŒ…è¯­éŸ³åˆæˆå¤§æ¨¡åž‹: {voice_id}...")
        
        # 3. æž„å»ºå‘½ä»¤è¡ŒæŒ‡ä»¤
        command = [
            sys.executable,  # ä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨
            script_path,
            "--appid", appid,
            "--access_token", access_token,
            "--voice_type", voice_id,
            "--text", text,
            "--encoding", "mp3",
            "--output", output_path  # æŒ‡å®šè¾“å‡ºè·¯å¾„
        ]
        
        # 4. æ‰§è¡Œè„šæœ¬
        result = subprocess.run(
            command, 
            check=True, 
            capture_output=True, 
            text=True,
            timeout=60  # 60ç§’è¶…æ—¶
        )
        
        # 5. éªŒè¯è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            print(f"âœ… è±†åŒ…å¤§æ¨¡åž‹éŸ³é¢‘æµæŽ¥æ”¶å®Œæ¯•ï¼éŸ³é¢‘å·²ä¿å­˜è‡³: {output_path}")
            return True
        else:
            print(f"âŒ è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆæˆ–ä¸ºç©º: {output_path}")
            return False
            
    except subprocess.TimeoutExpired:
        print("âŒ ç«å±±å¼•æ“Ž TTS è¶…æ—¶ï¼ˆ60ç§’ï¼‰")
        return False
    except subprocess.CalledProcessError as e:
        print(f"âŒ ç«å±±å¤§æ¨¡åž‹åˆæˆå¤±è´¥ï¼Œå®˜æ–¹è„šæœ¬æŠ¥é”™ä¿¡æ¯ï¼š")
        print(e.stderr)
        return False
    except Exception as e:
        print(f"âŒ ç«å±±å¼•æ“Ž TTS è°ƒç”¨å¼‚å¸¸: {e}")
        return False

async def text_to_mp3(text, filename, voice_id="zh-CN-YunxiNeural"):
    """ã€äº‘ç«¯ä¼˜åŒ–ç‰ˆã€‘ç›´æŽ¥è”ç½‘ç”Ÿæˆé…éŸ³ï¼Œå¢žåŠ é‡è¯•é€»è¾‘ã€‚æ”¯æŒå¤šè·¯ TTS è·¯ç”±ã€‚"""
    
    # ðŸŽ™ï¸ è·¯ç”± 1ï¼šç«å±±å¼•æ“Ž TTS (æ–¹è¨€ + é«˜æƒ…ç»ªè¡¨è¾¾)
    if voice_id.startswith("volc_"):
        # åŽ»æŽ‰å‰ç¼€ï¼ŒèŽ·å–çœŸå®žçš„éŸ³è‰² ID
        real_voice_id = voice_id.replace("volc_", "")
        success = call_volcengine_tts(text, real_voice_id, filename)
        if success:
            return True
        else:
            # ç«å±±å¼•æ“Žå¤±è´¥ï¼Œå›žé€€åˆ° Edge TTS
            print("âš ï¸ ç«å±±å¼•æ“Žä¸å¯ç”¨ï¼Œå›žé€€åˆ° Edge TTS æ¨¡å¼")
            voice_id = "zh-CN-YunxiNeural"  # ä½¿ç”¨é»˜è®¤ç”·å£°
    
    # ðŸŽ™ï¸ è·¯ç”± 2ï¼šEdge TTS (å…è´¹å…œåº•)
    for attempt in range(3):
        try:
            # åˆ é™¤äº† proxy å‚æ•°ï¼Œäº‘ç«¯ç›´è¿žé€Ÿåº¦æžå¿«
            communicate = edge_tts.Communicate(text, voice_id, rate="+10%")
            await communicate.save(filename)
            return True
        except Exception as e:
            print(f"TTS å°è¯• {attempt+1}/3 å¤±è´¥: {e}")
            await asyncio.sleep(2)
    return False

def generate_all_audios_sync(scenes_data, voice_id="zh-CN-YunxiNeural"):
    """ä¸²è¡Œç”Ÿæˆæ‰€æœ‰åˆ†é•œé…éŸ³"""
    audio_files = []
    for i, scene in enumerate(scenes_data):
        audio_file = f"temp_audio_{i}.mp3"
        st.toast(f"ðŸŽ™ï¸ AI é…éŸ³ç”Ÿæˆä¸­... {i+1}/{len(scenes_data)}")
        if asyncio.run(text_to_mp3(scene['narration'], audio_file, voice_id)):
            audio_files.append(audio_file)
        else:
            # å¤±è´¥å…œåº•é€»è¾‘
            audio_files.append(None)
        asyncio.run(asyncio.sleep(0.5))
    return audio_files

def render_ai_video_pipeline(scenes_data, zhipu_key, output_path, pexels_key=None, voice_id="zh-CN-YunxiNeural"):
    """æ ¸å¿ƒè§†é¢‘æ¸²æŸ“ç®¡çº¿"""
    from api_services import generate_images_zhipu
    
    # 1. èµ„æºç”Ÿæˆ
    image_paths = generate_images_zhipu(scenes_data, zhipu_key)
    audio_files = generate_all_audios_sync(scenes_data, voice_id)  # ä¼ é€’ voice_id
    
    # ðŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæˆåŠŸç”Ÿæˆçš„å›¾ç‰‡æ•°é‡
    success_count = sum(1 for p in image_paths if p)
    st.write(f"ðŸ“¸ æˆåŠŸç”Ÿæˆå›¾ç‰‡æ•°é‡: {success_count}/{len(image_paths)}")
    
    scene_clips = []
    temp_files = []

    # 2. é€åˆ†é•œåˆæˆ
    for i, scene in enumerate(scenes_data):
        if not audio_files[i]: 
            st.warning(f"âš ï¸ åˆ†é•œ {i+1} éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡")
            continue
            
        audio_clip = AudioFileClip(audio_files[i])
        dur = audio_clip.duration
        temp_files.append(audio_files[i])
        
        # ç”»é¢é€»è¾‘ï¼šAIç»˜ç”» > é»‘å±å ä½
        if image_paths[i]:
            st.write(f"ðŸ–¼ï¸ åˆ†é•œ {i+1} ä½¿ç”¨AIç»˜ç”»: {image_paths[i]}")
            try:
                # ðŸ”‘ æ ¸å¿ƒä¿®å¤ï¼šç”¨ Pillow é¢„å¤„ç†å›¾ç‰‡ï¼Œé¿å… MoviePy çš„ resize è§¦å‘ ANTIALIAS
                from PIL import Image as PILImage
                img = PILImage.open(image_paths[i])
                
                # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆç›®æ ‡é«˜åº¦ 1920ï¼‰
                scale = 1920 / img.height
                new_width = int(img.width * scale)
                
                # ä½¿ç”¨ Pillow çš„ LANCZOS é‡é‡‡æ ·ï¼ˆå…¼å®¹æ–°æ—§ç‰ˆæœ¬ï¼‰
                try:
                    # Pillow >= 10.0.0
                    img_resized = img.resize((new_width, 1920), PILImage.Resampling.LANCZOS)
                except AttributeError:
                    # Pillow < 10.0.0
                    img_resized = img.resize((new_width, 1920), PILImage.LANCZOS)
                
                # è£å‰ªåˆ° 1080x1920ï¼ˆå±…ä¸­è£å‰ªï¼‰
                left = (new_width - 1080) // 2
                img_cropped = img_resized.crop((left, 0, left + 1080, 1920))
                
                # è½¬ä¸º numpy æ•°ç»„ï¼Œä¼ ç»™ MoviePyï¼ˆä¸å†è°ƒç”¨ resizeï¼‰
                img_array = np.array(img_cropped)
                bg = ImageClip(img_array).set_duration(dur)
                temp_files.append(image_paths[i])
                st.success(f"âœ… åˆ†é•œ {i+1} å›¾ç‰‡å¤„ç†æˆåŠŸ")
            except Exception as e:
                st.error(f"âŒ åˆ†é•œ {i+1} å›¾ç‰‡åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»‘å±å ä½")
                bg = ColorClip(size=(1080, 1920), color=(0, 0, 0)).set_duration(dur)
        else:
            st.write(f"âš« åˆ†é•œ {i+1} å›¾ç‰‡ä¸ºç©ºï¼Œä½¿ç”¨é»‘å±å ä½")
            # ðŸ”‘ ä¿®å¤ï¼šä½¿ç”¨ ColorClip åˆ›å»ºçº¯é»‘èƒŒæ™¯
            bg = ColorClip(size=(1080, 1920), color=(0, 0, 0)).set_duration(dur)

        # ðŸŽ¨ å­—å¹•é€»è¾‘ï¼šç”¨ Pillow æ‰‹å·¥ç»˜åˆ¶ + æ­£ç¡®å¤„ç†é€æ˜Žåº¦
        subtitle_rgba = create_subtitle_image(scene['narration'], width=1080, height=400, fontsize=70)
        
        # ðŸ”‘ æ ¸å¿ƒä¿®å¤ï¼šæ‹†åˆ† RGB å’Œ Alpha é€šé“ï¼Œç¡®ä¿é€æ˜Žåº¦æ­£ç¡®
        # RGBA æ•°ç»„çš„å‰3ä¸ªé€šé“æ˜¯é¢œè‰²ï¼Œç¬¬4ä¸ªé€šé“æ˜¯é€æ˜Žåº¦
        rgb_array = subtitle_rgba[:, :, :3]  # å–å‰3ä¸ªé€šé“ï¼ˆRGBï¼‰
        alpha_array = subtitle_rgba[:, :, 3] / 255.0  # å–ç¬¬4ä¸ªé€šé“ï¼ˆAlphaï¼‰ï¼Œå½’ä¸€åŒ–åˆ°0-1
        
        # åˆ›å»ºå­—å¹•å›¾å±‚ï¼Œæ˜Žç¡®æŒ‡å®š mask
        txt_clip = ImageClip(rgb_array).set_duration(dur)
        txt_clip = txt_clip.set_mask(ImageClip(alpha_array, ismask=True).set_duration(dur))
        txt_clip = txt_clip.set_position(('center', 0.75), relative=True)
        
        scene_clips.append(CompositeVideoClip([bg, txt_clip]).set_audio(audio_clip))

    # 3. æœ€ç»ˆåŽ‹åˆ¶ä¸Ž BGM æ··éŸ³
    if not scene_clips: return False
    
    final = concatenate_videoclips(scene_clips, method="compose")
    
    if os.path.exists("bgm.mp3"):
        bgm = AudioFileClip("bgm.mp3").volumex(0.08).set_duration(final.duration)
        final = final.set_audio(CompositeAudioClip([final.audio, bgm]))

    # 4. å¯¼å‡º (ä¼˜åŒ–å‚æ•°é˜²æ­¢äº‘ç«¯å†…å­˜æº¢å‡º)
    final.write_videofile(output_path, fps=24, codec="libx264", audio_codec="aac", 
                          threads=4, preset="ultrafast", logger=None)
    
    # 5. èµ„æºæ¸…ç†
    final.close()
    for f in temp_files:
        if f and os.path.exists(f): 
            try: os.remove(f)
            except: pass
    return True
