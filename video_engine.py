import os
import platform
import asyncio
import edge_tts
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import streamlit as st
from moviepy.editor import AudioFileClip, ImageClip, ColorClip, CompositeVideoClip, concatenate_videoclips, CompositeAudioClip

# ğŸ”‘ å­—ä½“è·¯å¾„é…ç½®ï¼šå¤šçº§é™çº§ç­–ç•¥ç¡®ä¿100%å¯ç”¨
def get_font_path():
    """æ™ºèƒ½æ£€æµ‹å¯ç”¨çš„ä¸­æ–‡å­—ä½“è·¯å¾„"""
    # 1. ä¼˜å…ˆï¼šä»“åº“ä¸­çš„å­—ä½“æ–‡ä»¶ï¼ˆç»å¯¹è·¯å¾„ï¼‰
    repo_font = os.path.join(os.path.dirname(__file__), "font.ttf")
    if os.path.exists(repo_font):
        return repo_font
    
    # 2. é™çº§ï¼šå½“å‰å·¥ä½œç›®å½•çš„å­—ä½“æ–‡ä»¶
    if os.path.exists("font.ttf"):
        return os.path.abspath("font.ttf")
    
    # 3. æœ€ç»ˆé™çº§ï¼šå¯»æ‰¾ç³»ç»Ÿå­—ä½“æ–‡ä»¶
    if platform.system() == "Linux":
        linux_fonts = [
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
        ]
        for font in linux_fonts:
            if os.path.exists(font):
                return font
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å› Noneï¼ˆåç»­ä¼šæœ‰é”™è¯¯æç¤ºï¼‰
    return None

FONT_PATH = get_font_path()

# ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šåœ¨ Streamlit ä¾§è¾¹æ æ˜¾ç¤ºå­—ä½“è·¯å¾„
try:
    if st and hasattr(st, 'sidebar'):
        with st.sidebar:
            if FONT_PATH:
                st.success(f"âœ… å­—ä½“åŠ è½½æˆåŠŸ: {os.path.basename(FONT_PATH)}")
            else:
                st.error("âŒ æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ï¼è¯·ä¸Šä¼  font.ttf")
except:
    pass  # é Streamlit ç¯å¢ƒä¸‹å¿½ç•¥

def create_subtitle_image(text, width=1080, height=400, fontsize=70):
    """ğŸ¨ ç”¨ Pillow æ‰‹å·¥ç»˜åˆ¶å­—å¹•å›¾ç‰‡ï¼ˆå½»åº•ç»•è¿‡ ImageMagickï¼‰"""
    if not FONT_PATH:
        raise FileNotFoundError("æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ï¼è¯·ç¡®ä¿ font.ttf å­˜åœ¨äºä»“åº“æ ¹ç›®å½•")
    
    # åˆ›å»ºé€æ˜èƒŒæ™¯å›¾ç‰‡
    img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # åŠ è½½å­—ä½“
    try:
        font = ImageFont.truetype(FONT_PATH, fontsize)
    except Exception as e:
        st.error(f"å­—ä½“åŠ è½½å¤±è´¥: {e}")
        raise
    
    # æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œ
    lines = []
    words = text
    max_width = width - 100  # å·¦å³è¾¹è·50px
    
    # ç®€å•æ¢è¡Œé€»è¾‘ï¼šæŒ‰å­—ç¬¦å®½åº¦åˆ‡åˆ†
    current_line = ""
    for char in words:
        test_line = current_line + char
        bbox = draw.textbbox((0, 0), test_line, font=font)
        if bbox[2] - bbox[0] > max_width and current_line:
            lines.append(current_line)
            current_line = char
        else:
            current_line = test_line
    if current_line:
        lines.append(current_line)
    
    # è®¡ç®—æ€»é«˜åº¦å¹¶å±…ä¸­
    line_height = fontsize + 20
    total_height = len(lines) * line_height
    start_y = (height - total_height) // 2
    
    # ç»˜åˆ¶æ¯è¡Œæ–‡å­—ï¼ˆå…ˆç”»é»‘è¾¹ï¼Œå†ç”»ç™½å­—ï¼‰
    for i, line in enumerate(lines):
        bbox = draw.textbbox((0, 0), line, font=font)
        text_width = bbox[2] - bbox[0]
        x = (width - text_width) // 2
        y = start_y + i * line_height
        
        # é»‘è‰²æè¾¹ï¼ˆstrokeæ•ˆæœï¼‰
        for offset_x in [-2, 0, 2]:
            for offset_y in [-2, 0, 2]:
                if offset_x != 0 or offset_y != 0:
                    draw.text((x + offset_x, y + offset_y), line, font=font, fill=(0, 0, 0, 255))
        
        # ç™½è‰²ä¸»æ–‡å­—
        draw.text((x, y), line, font=font, fill=(255, 255, 255, 255))
    
    # è½¬ä¸º numpy æ•°ç»„ä¾› MoviePy ä½¿ç”¨
    return np.array(img)

async def text_to_mp3(text, filename):
    """ã€äº‘ç«¯ä¼˜åŒ–ç‰ˆã€‘ç›´æ¥è”ç½‘ç”Ÿæˆé…éŸ³ï¼Œå¢åŠ é‡è¯•é€»è¾‘"""
    for attempt in range(3):
        try:
            # åˆ é™¤äº† proxy å‚æ•°ï¼Œäº‘ç«¯ç›´è¿é€Ÿåº¦æå¿«
            communicate = edge_tts.Communicate(text, "zh-CN-YunxiNeural", rate="+10%")
            await communicate.save(filename)
            return True
        except Exception as e:
            print(f"TTS å°è¯• {attempt+1}/3 å¤±è´¥: {e}")
            await asyncio.sleep(2)
    return False

def generate_all_audios_sync(scenes_data):
    """ä¸²è¡Œç”Ÿæˆæ‰€æœ‰åˆ†é•œé…éŸ³"""
    audio_files = []
    for i, scene in enumerate(scenes_data):
        audio_file = f"temp_audio_{i}.mp3"
        st.toast(f"ğŸ™ï¸ AI é…éŸ³ç”Ÿæˆä¸­... {i+1}/{len(scenes_data)}")
        if asyncio.run(text_to_mp3(scene['narration'], audio_file)):
            audio_files.append(audio_file)
        else:
            # å¤±è´¥å…œåº•é€»è¾‘
            audio_files.append(None)
        asyncio.run(asyncio.sleep(0.5))
    return audio_files

def render_ai_video_pipeline(scenes_data, zhipu_key, output_path, pexels_key=None):
    """æ ¸å¿ƒè§†é¢‘æ¸²æŸ“ç®¡çº¿"""
    from api_services import generate_images_zhipu
    
    # 1. èµ„æºç”Ÿæˆ
    image_paths = generate_images_zhipu(scenes_data, zhipu_key)
    audio_files = generate_all_audios_sync(scenes_data)
    
    # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæˆåŠŸç”Ÿæˆçš„å›¾ç‰‡æ•°é‡
    success_count = sum(1 for p in image_paths if p)
    st.write(f"ğŸ“¸ æˆåŠŸç”Ÿæˆå›¾ç‰‡æ•°é‡: {success_count}/{len(image_paths)}")
    
    scene_clips = []
    temp_files = []

    # 2. é€åˆ†é•œåˆæˆ
    for i, scene in enumerate(scenes_data):
        if not audio_files[i]: continue
            
        audio_clip = AudioFileClip(audio_files[i])
        dur = audio_clip.duration
        temp_files.append(audio_files[i])
        
        # ç”»é¢é€»è¾‘ï¼šAIç»˜ç”» > é»‘å±å ä½
        if image_paths[i]:
            bg = ImageClip(image_paths[i]).set_duration(dur).resize(height=1920).crop(x_center=1080/2, width=1080)
            temp_files.append(image_paths[i])
        else:
            # ğŸ”‘ ä¿®å¤ï¼šä½¿ç”¨ ColorClip åˆ›å»ºçº¯é»‘èƒŒæ™¯
            bg = ColorClip(size=(1080, 1920), color=(0, 0, 0)).set_duration(dur)

        # ğŸ¨ å­—å¹•é€»è¾‘ï¼šç”¨ Pillow æ‰‹å·¥ç»˜åˆ¶ + æ­£ç¡®å¤„ç†é€æ˜åº¦
        subtitle_rgba = create_subtitle_image(scene['narration'], width=1080, height=400, fontsize=70)
        
        # ğŸ”‘ æ ¸å¿ƒä¿®å¤ï¼šæ‹†åˆ† RGB å’Œ Alpha é€šé“ï¼Œç¡®ä¿é€æ˜åº¦æ­£ç¡®
        # RGBA æ•°ç»„çš„å‰3ä¸ªé€šé“æ˜¯é¢œè‰²ï¼Œç¬¬4ä¸ªé€šé“æ˜¯é€æ˜åº¦
        rgb_array = subtitle_rgba[:, :, :3]  # å–å‰3ä¸ªé€šé“ï¼ˆRGBï¼‰
        alpha_array = subtitle_rgba[:, :, 3] / 255.0  # å–ç¬¬4ä¸ªé€šé“ï¼ˆAlphaï¼‰ï¼Œå½’ä¸€åŒ–åˆ°0-1
        
        # åˆ›å»ºå­—å¹•å›¾å±‚ï¼Œæ˜ç¡®æŒ‡å®š mask
        txt_clip = ImageClip(rgb_array).set_duration(dur)
        txt_clip = txt_clip.set_mask(ImageClip(alpha_array, ismask=True).set_duration(dur))
        txt_clip = txt_clip.set_position(('center', 0.75), relative=True)
        
        scene_clips.append(CompositeVideoClip([bg, txt_clip]).set_audio(audio_clip))

    # 3. æœ€ç»ˆå‹åˆ¶ä¸ BGM æ··éŸ³
    if not scene_clips: return False
    
    final = concatenate_videoclips(scene_clips, method="compose")
    
    if os.path.exists("bgm.mp3"):
        bgm = AudioFileClip("bgm.mp3").volumex(0.08).set_duration(final.duration)
        final = final.set_audio(CompositeAudioClip([final.audio, bgm]))

    # 4. å¯¼å‡º (ä¼˜åŒ–å‚æ•°é˜²æ­¢äº‘ç«¯å†…å­˜æº¢å‡º)
    final.write_videofile(output_path, fps=24, codec="libx264", audio_codec="aac", 
                          threads=4, preset="ultrafast", logger=None)
    
    # 5. èµ„æºæ¸…ç†
    final.close()
    for f in temp_files:
        if f and os.path.exists(f): 
            try: os.remove(f)
            except: pass
    return True
